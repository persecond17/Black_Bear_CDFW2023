{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "z4TVrvhj36f0",
    "outputId": "7940936d-665a-4eda-e4b8-b2226d254ca5"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
      "[nltk_data] Downloading package omw-1.4 to /root/nltk_data...\n",
      "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
      "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
      "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import glob\n",
    "import random\n",
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.decomposition import NMF, PCA\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, cross_val_predict, GridSearchCV\n",
    "from sklearn.metrics import mean_squared_error, f1_score, confusion_matrix, accuracy_score, classification_report\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "from keras.models import Model, Sequential\n",
    "from keras.preprocessing.text import Tokenizer, text_to_word_sequence\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from keras.layers import Dense, Flatten, Embedding\n",
    "from keras.optimizers import Adam\n",
    "from keras.utils import plot_model\n",
    "import multiprocessing\n",
    "from matplotlib import pyplot\n",
    "from gensim.models import Word2Vec\n",
    "from csv import DictWriter\n",
    "from collections import Counter\n",
    "from dateutil import parser\n",
    "%matplotlib inline\n",
    "import warnings \n",
    "warnings.filterwarnings(action = 'ignore') \n",
    "\n",
    "nltk.download('wordnet')\n",
    "nltk.download('omw-1.4')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "stop_words = set(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "QLfIwZASBscV",
    "outputId": "e9289163-d515-4dd8-9596-3836b1300ead"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/drive/\n",
      "/content/drive/My Drive/practicum_data\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive/', force_remount=True)\n",
    "%cd /content/drive/My Drive/practicum_data/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JUVQ-W0jS1aL"
   },
   "source": [
    "# Preprocessing: Merging, Tokenizing, and Vectorizing Labeled Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "AgqwWFCj37xk"
   },
   "outputs": [],
   "source": [
    "def merge_csv() -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Obtain a list of all CSV files in a given directory, \n",
    "    iterate through each CSV file and load it into a DataFrame. \n",
    "    Concatenate all the DataFrames into a single one. Parse dates \n",
    "    and remove any duplicate rows based on the tweet_id column.\n",
    "    \"\"\"\n",
    "    csv_files = glob.glob('*.csv')\n",
    "    df_list = []\n",
    "    for file in csv_files:\n",
    "        if not file.startswith('stage_2'):\n",
    "            df = pd.read_csv(file)\n",
    "            df_list.append(df)\n",
    "\n",
    "    df = pd.concat(df_list, axis=0, ignore_index=True)\n",
    "    df['created_datetime'] = df['created_datetime'].apply(parser.parse)\\\n",
    "                                .apply(lambda x: x.strftime('%Y-%m-%d'))\n",
    "    df['created_datetime'] = pd.to_datetime(df['created_datetime'])\n",
    "    df.drop_duplicates(subset=['tweet_id'], inplace=True)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "KsiAnmepmwu-"
   },
   "outputs": [],
   "source": [
    "def text_clean_and_tokenize(text: str) -> object:\n",
    "    '''\n",
    "    Preprocess the text data by removing URLs, hashtags, \n",
    "    punctuations, and extra spaces. Convert uppercase \n",
    "    letters to lowercase, tokenize the words, remove \n",
    "    stopwords, and perform text lemmatization.\n",
    "    '''\n",
    "    text = re.sub(r'http\\S+', '', text)\n",
    "    text = re.sub(r'#\\w+|\\@\\w+', '', text)\n",
    "    text  = \"\".join((char if char.isalpha() else \" \") for char in text)\n",
    "    text = re.sub('[\\W_]+', ' ', text)\n",
    "    text = re.sub(' +', ' ',text)\n",
    "    text = text.strip()\n",
    "    text = text.lower()\n",
    "    text = nltk.word_tokenize(text)#re.split('\\W+', text)\n",
    "    text = [word for word in text if word not in stop_words]\n",
    "\n",
    "    ps = nltk.WordNetLemmatizer()\n",
    "    text = [ps.lemmatize(w) for w in text]\n",
    "    merged_text = ' '.join(text)\n",
    "    return text, merged_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "x0CI_rVIB4sj",
    "outputId": "3d516cf0-e541-4ecd-be16-7a24e29986ca"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label\n",
      "0    1293\n",
      "1     520\n",
      "2     280\n",
      "Name: label, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "df = merge_csv().reset_index(drop=True)\n",
    "print(df.groupby('label')['label'].count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "g2pO5d165grC",
    "outputId": "cd9ea560-306c-46aa-9008-2abc9419412b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2093 entries, 0 to 2092\n",
      "Data columns (total 13 columns):\n",
      " #   Column            Non-Null Count  Dtype         \n",
      "---  ------            --------------  -----         \n",
      " 0   tweet_id          2093 non-null   float64       \n",
      " 1   created_datetime  2093 non-null   datetime64[ns]\n",
      " 2   content           2093 non-null   object        \n",
      " 3   author_id         2093 non-null   float64       \n",
      " 4   place_id          2061 non-null   object        \n",
      " 5   location          2061 non-null   object        \n",
      " 6   longitude         2093 non-null   float64       \n",
      " 7   latitude          2093 non-null   float64       \n",
      " 8   county            2093 non-null   object        \n",
      " 9   label             2093 non-null   int64         \n",
      " 10  tokenized_tweets  2093 non-null   object        \n",
      " 11  tokenized         2093 non-null   object        \n",
      " 12  merged            2093 non-null   object        \n",
      "dtypes: datetime64[ns](1), float64(4), int64(1), object(7)\n",
      "memory usage: 212.7+ KB\n"
     ]
    }
   ],
   "source": [
    "df['tokenized_tweets'] = df['content'].apply(lambda x: text_clean_and_tokenize(x))\n",
    "df[['tokenized', 'merged']] = df['tokenized_tweets'].apply(lambda x: pd.Series(x))\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Od7_wkIMW6uc"
   },
   "source": [
    "# Warm-up: Splitting Training/Test Sets and Defining Performance Function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eUJOJ7gHsgJG"
   },
   "source": [
    "We split the labeled dataset into training and test sets with a ratio of 0.9 and 0.1, respectively. This ratio is chosen to provide sufficient training data for the text classification models to capture the data structures.\n",
    "\n",
    "For text representation, we decided to use TF-IDF instead of GloVe embeddings like [the previous step](https://github.com/persecond17/Black_Bear_CDFW2023/blob/main/social_media_NLP_project/step_3_data_transformation/2_labeling.ipynb). While GloVe embeddings are pre-trained on large corpora and can effectively capture semantic relationships between words, TF-IDF is more suitable for handling a greater number of unique words and identifying important words in a given document, especially when there are more labeled records available."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wPHjVD8GXKw2",
    "outputId": "69f4a7f6-67d4-4687-9fff-baad6278cf25"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((2093, 3524), (1883, 3524), (210, 3524))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X, y = df['merged'], df['label']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=.1, random_state=42)\n",
    "\n",
    "tfidf = TfidfVectorizer(stop_words=list(stop_words))\n",
    "tfidf.fit(X)\n",
    "X_vectors = tfidf.transform(X)\n",
    "X_train_vectors = tfidf.transform(X_train)\n",
    "X_test_vectors = tfidf.transform(X_test)\n",
    "\n",
    "X_vectors.shape, X_train_vectors.shape, X_test_vectors.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "CmRFxuxRf_5D"
   },
   "outputs": [],
   "source": [
    "def print_performance(y_test, y_pred):\n",
    "    \"\"\"\n",
    "    Compute the F1 score, accuracy, MSE (mean squared error) \n",
    "    and confusion matrix for the true values and predicted \n",
    "    values of a test dataset.\n",
    "    \"\"\"\n",
    "    f1 = f1_score(y_test, y_pred, average='weighted')\n",
    "    ac = accuracy_score(y_test, y_pred)\n",
    "    mse = mean_squared_error(y_test, y_pred)\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "    print(\"F1 score: \", f1)\n",
    "    print(\"Accuracy: \", ac)\n",
    "    print(\"MSE: \", mse)\n",
    "    print(\"Confusion matrix: \")\n",
    "    print(cm)\n",
    "    # return f1, ac, cm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5eHe0qThyEcp"
   },
   "source": [
    "In the upcoming chapter, I will explore six text classification models for our classification task. Each chapter will begin by introducing the baseline model, followed by tuning it through grid search, applying dimensionality reduction techniques, and implementing feature selection methods. The final model will be selected for ensemble modeling purposes.\n",
    "\n",
    "Notes:\n",
    "* I chose **grid search** since it's appropriate for small hyperparameter spaces and limited resources. \n",
    "* To reduce dimensionality, I applied **Principal Component Analysis (PCA)** and **Non-Negative Matrix Factorization (NMF)**. PCA transforms high-dimensional data into a smaller set of orthogonal components that capture the most significant information in the original data. NMF factors a non-negative matrix into the product of two non-negative matrices with lower rank.\n",
    "* For feature selection, I used **Recursive Feature Elimination (RFE)**. RFE recursively removes features from the dataset and builds a model using the remaining features. It then ranks the features by their importance and removes the least important feature. This process repeats until the desired number of features is reached."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "S7JyU913XFuI"
   },
   "source": [
    "# Model 1: Naive Bayes (`MultinomialNB`)\n",
    "* Assumes that the features are discrete and follow a multinomial distribution\n",
    "* Commonly used for text classification problems where the features are word frequencies or counts\n",
    "* Specifically designed to work with sparse input"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BlzO_eAfpJq_"
   },
   "source": [
    "### Baseline of NB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "B9dHZKEpdq8z",
    "outputId": "b5e912d9-ebe9-4440-c32b-f3e2a1f0c32b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 score:  0.7056840230784459\n",
      "Accuracy:  0.7523809523809524\n",
      "MSE:  0.46190476190476193\n",
      "Confusion matrix: \n",
      "[[132   1   0]\n",
      " [ 34  24   0]\n",
      " [ 15   2   2]]\n"
     ]
    }
   ],
   "source": [
    "nb = MultinomialNB()\n",
    "nb.fit(X_train_vectors, y_train)\n",
    "y_pred = nb.predict(X_test_vectors)\n",
    "\n",
    "print_performance(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MTI1ROkjpMV3"
   },
   "source": [
    "### Tune NB: Grid search best parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "l8e-LMqqXgJX",
    "outputId": "e06b3966-7e47-41a4-a0bd-b81433df5ad5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 score:  0.7825893714505198\n",
      "Accuracy:  0.7761904761904762\n",
      "MSE:  0.4238095238095238\n",
      "Confusion matrix: \n",
      "[[108  15  10]\n",
      " [  7  47   4]\n",
      " [  4   7   8]]\n",
      "Best hyperparameters:  {'alpha': 1.4000000000000001, 'fit_prior': False}\n"
     ]
    }
   ],
   "source": [
    "nb = MultinomialNB()\n",
    "param_grid = {\n",
    "    'alpha': [x * 0.1 for x in range(1, 20)],\n",
    "    'fit_prior': [True, False]\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(nb, param_grid, cv=5)\n",
    "grid_search.fit(X_train_vectors, y_train)\n",
    "y_pred = grid_search.predict(X_test_vectors)\n",
    "\n",
    "print_performance(y_test, y_pred)\n",
    "print(\"Best hyperparameters: \", grid_search.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LHeLlWYjb7Ni"
   },
   "source": [
    "Used grid search to optimize the hyperparameters of Multinomial Naive Bayes on our dataset, specifically \"alpha\" (0.1 to 2.0) and \"fit_prior\" (True/False). The best combination of hyperparameters was found to be {'alpha': 1.4, 'fit_prior': False}. With these optimal hyperparameters, the trained model achieved an F1 score of 0.783 and an accuracy of 0.776."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ElL-I7QFpUBZ"
   },
   "source": [
    "### Turn NB: Non-negative Matrix Factorization (NMF)\n",
    "\n",
    "* NMF is particularly useful for non-negative data, and it produces non-negative weights and components.\n",
    "* NMF can be used to reduce the dimensionality while still preserving the sparsity structure of the data.\n",
    "* Compare with other dimensionality reduction techniques: \n",
    "1) PCA does not support sparse input data and may create negative output; 2) SVM can be used in sparse matrix, but may create negative output as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 295
    },
    "id": "dW_eJNH7ETGV",
    "outputId": "4fe60f1d-eef7-4dea-be4d-fc6a1bce0c0c"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "n_components_range = range(1, 200, 20)\n",
    "reconstruction_errors = []\n",
    "\n",
    "for n_components in n_components_range:\n",
    "    model = NMF(n_components=n_components, random_state=42)\n",
    "    W = model.fit_transform(X_train_vectors)\n",
    "    H = model.components_\n",
    "    X_approx = np.dot(W, H)\n",
    "    reconstruction_error = np.mean(np.square((X_train_vectors - X_approx).flatten()))\n",
    "    reconstruction_errors.append(reconstruction_error)\n",
    "\n",
    "# plot the scree plot\n",
    "plt.plot(n_components_range, reconstruction_errors, 'o-')\n",
    "plt.xlabel('Number of components')\n",
    "plt.ylabel('Reconstruction error')\n",
    "plt.title('Scree plot for NMF')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "kyUNGC3wxbyF",
    "outputId": "3194ff11-788d-49fc-b272-f28a83a1789f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 score:  0.7118506660675337\n",
      "Accuracy:  0.7047619047619048\n",
      "MSE:  0.49523809523809526\n",
      "Confusion matrix: \n",
      "[[99 24 10]\n",
      " [13 42  3]\n",
      " [ 4  8  7]]\n"
     ]
    }
   ],
   "source": [
    "nmf = NMF(n_components=700, random_state=42)\n",
    "X_train_nmf = nmf.fit_transform(X_train_vectors)\n",
    "X_test_nmf = nmf.transform(X_test_vectors)\n",
    "\n",
    "nb = MultinomialNB(alpha=1.4, fit_prior=False)\n",
    "nb.fit(X_train_nmf, y_train)\n",
    "y_pred = nb.predict(X_test_nmf)\n",
    "\n",
    "print_performance(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-v5qoNd0diqA"
   },
   "source": [
    "Upon evaluation, it appears that utilizing NMF did not result in a significant improvement in model performance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "i6RtmaFTMxqN"
   },
   "source": [
    "### Turn NB: Feature Selection with RFE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "hyf4-tlvM3yE",
    "outputId": "f318927d-c5dd-4f71-a16d-90b3252b2980"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Select 900 features:\n",
      "F1 score:  0.7685126616833934\n",
      "Accuracy:  0.7619047619047619\n",
      "MSE:  0.3952380952380952\n",
      "Confusion matrix: \n",
      "[[103  23   7]\n",
      " [  6  48   4]\n",
      " [  4   6   9]]\n",
      "Select 1200 features:\n",
      "F1 score:  0.7933247690968279\n",
      "Accuracy:  0.7904761904761904\n",
      "MSE:  0.3523809523809524\n",
      "Confusion matrix: \n",
      "[[111  16   6]\n",
      " [  7  47   4]\n",
      " [  4   7   8]]\n",
      "Select 1500 features:\n",
      "F1 score:  0.798143709468223\n",
      "Accuracy:  0.7952380952380952\n",
      "MSE:  0.3476190476190476\n",
      "Confusion matrix: \n",
      "[[112  15   6]\n",
      " [  8  46   4]\n",
      " [  4   6   9]]\n",
      "Select 1800 features:\n",
      "F1 score:  0.7899080106644066\n",
      "Accuracy:  0.7904761904761904\n",
      "MSE:  0.3523809523809524\n",
      "Confusion matrix: \n",
      "[[114  14   5]\n",
      " [  9  45   4]\n",
      " [  5   7   7]]\n",
      "Select 2100 features:\n",
      "F1 score:  0.8061560682160743\n",
      "Accuracy:  0.8095238095238095\n",
      "MSE:  0.3047619047619048\n",
      "Confusion matrix: \n",
      "[[118  12   3]\n",
      " [  9  45   4]\n",
      " [  5   7   7]]\n",
      "Select 2400 features:\n",
      "F1 score:  0.7952403651280056\n",
      "Accuracy:  0.8\n",
      "MSE:  0.34285714285714286\n",
      "Confusion matrix: \n",
      "[[118  11   4]\n",
      " [ 10  44   4]\n",
      " [  6   7   6]]\n",
      "Select 2700 features:\n",
      "F1 score:  0.7916153127917834\n",
      "Accuracy:  0.7952380952380952\n",
      "MSE:  0.3619047619047619\n",
      "Confusion matrix: \n",
      "[[117  11   5]\n",
      " [ 10  44   4]\n",
      " [  6   7   6]]\n",
      "Select 3000 features:\n",
      "F1 score:  0.7756885226038023\n",
      "Accuracy:  0.7761904761904762\n",
      "MSE:  0.4095238095238095\n",
      "Confusion matrix: \n",
      "[[113  13   7]\n",
      " [ 10  44   4]\n",
      " [  6   7   6]]\n",
      "Select 3300 features:\n",
      "F1 score:  0.7928847161853247\n",
      "Accuracy:  0.7952380952380952\n",
      "MSE:  0.3761904761904762\n",
      "Confusion matrix: \n",
      "[[114  13   6]\n",
      " [  8  47   3]\n",
      " [  6   7   6]]\n"
     ]
    }
   ],
   "source": [
    "n = X_train_vectors.shape[1]\n",
    "n_features_range = range(900, n, 300)\n",
    "selected_dict_nb = dict()\n",
    "for n_features in n_features_range: \n",
    "    estimator = LogisticRegression()\n",
    "    selector = RFE(estimator, n_features_to_select=n_features)\n",
    "    selector = selector.fit(X_train_vectors, y_train)\n",
    "\n",
    "    selected_feature_indices = selector.get_support(indices=True)\n",
    "    selected_train_nb = X_train_vectors[:,selected_feature_indices]\n",
    "    selected_test_nb = X_test_vectors[:,selected_feature_indices]\n",
    "    selected_dict_nb[n_features] = selected_feature_indices\n",
    "\n",
    "    nb = MultinomialNB(alpha=1.4, fit_prior=False)\n",
    "    nb.fit(selected_train_nb, y_train)\n",
    "    y_pred = nb.predict(selected_test_nb)\n",
    "    print(f\"Select {n_features} features:\")\n",
    "    print_performance(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Amyb1Hy1fZEp",
    "outputId": "3e723acc-41ac-40f1-dd89-187f1f337486"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1883, 2100), (210, 2100))"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "selected_features_nb = selected_dict_nb[2100]\n",
    "X_train_updated_nb = X_train_vectors[:,selected_features_nb]\n",
    "X_test_updated_nb = X_test_vectors[:,selected_features_nb]\n",
    "X_train_updated_nb.shape, X_test_updated_nb.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4A_TOKqtzaAd",
    "outputId": "0894d1dd-0bbc-40f3-9a6a-984fbf3d2193"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3.000e+00, 4.000e+00, 6.000e+00, ..., 3.517e+03, 3.520e+03,\n",
       "       3.521e+03])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# np.savetxt('selected_features_nb.txt', selected_features_nb, delimiter='\\t')\n",
    "arr_nb = np.loadtxt('selected_features_nb.txt', delimiter='\\t')\n",
    "arr_nb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QU25hnhKd6AE"
   },
   "source": [
    "Our evaluation showed that reducing the number of features in the NB model improved its performance. We have selected **2100 features** as the optimal configuration, achieving an F1 score of 0.806 and an accuracy of 0.810. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ffmgIoRTpWl0"
   },
   "source": [
    "### Final NB with the whole X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9PzKBJhIXcdW",
    "outputId": "cc218b89-8fb1-4123-d381-cdefad5d2374"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 score:  0.8007811848115548\n",
      "Accuracy:  0.7998088867654085\n",
      "MSE:  0.38365981844242714\n",
      "Confusion matrix: \n",
      "[[1114   99   80]\n",
      " [  57  425   38]\n",
      " [  48   97  135]]\n"
     ]
    }
   ],
   "source": [
    "final_nb = MultinomialNB(alpha=1.4, fit_prior=False)\n",
    "X_updated_nb = X_vectors[:, selected_features_nb]\n",
    "y_pred = cross_val_predict(final_nb, X_updated_nb, y, cv=5)\n",
    "\n",
    "print_performance(y, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9_bznnXn8cj2"
   },
   "source": [
    "After identifying the optimal hyperparameters through grid search and applying feature selection with RFE, we fine-tuned the Naive Bayes model. As a result, we achieved an **F1 score of 0.801** and an **accuracy of 0.800**, indicating a good performance of the model in predicting the target variable."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZD-4TqTEXHwu"
   },
   "source": [
    "# Model 2: Random Forest\n",
    "\n",
    "* Random forest is an ensemble learning method that constructs a multitude of decision trees at training time and outputs the class that is the mode of the classes (classification). \n",
    "* It offers advantages such as handling missing values, reducing overfitting, and providing feature importance rankings."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Wvwq_4Gq5mdJ"
   },
   "source": [
    "### Baseline of RF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ULOS6Ze5XLGH",
    "outputId": "cac0bcc2-1b62-4c0e-9489-843a1782ae11"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 score:  0.8138122653693142\n",
      "Accuracy:  0.8285714285714286\n",
      "MSE:  0.2714285714285714\n",
      "Confusion matrix: \n",
      "[[128   5   0]\n",
      " [ 16  40   2]\n",
      " [  7   6   6]]\n"
     ]
    }
   ],
   "source": [
    "rf = RandomForestClassifier(n_estimators=100) # 100 trees\n",
    "rf.fit(X_train_vectors, y_train)\n",
    "y_pred = rf.predict(X_test_vectors)\n",
    "\n",
    "print_performance(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YbosFRm_5jxy"
   },
   "source": [
    "### Tune RF: Grid search best parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "PfoOxqoZk79N",
    "outputId": "0eba165f-dd39-417c-a39d-4a58f241418f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 54 candidates, totalling 270 fits\n",
      "F1 score:  0.8160915039788279\n",
      "Accuracy:  0.8333333333333334\n",
      "MSE:  0.28095238095238095\n",
      "Confusion matrix: \n",
      "[[128   5   0]\n",
      " [ 15  42   1]\n",
      " [  8   6   5]]\n",
      "Best hyperparameters:  {'max_depth': None, 'max_features': 'auto', 'n_estimators': 500}\n"
     ]
    }
   ],
   "source": [
    "rf = RandomForestClassifier(random_state=42)\n",
    "param_grid = {\n",
    "    'n_estimators': [50, 100, 200, 300, 400, 500],\n",
    "    'max_depth': [None, 5, 10],\n",
    "    'max_features': ['auto', 'sqrt', 'log2']\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(\n",
    "    estimator=rf,\n",
    "    param_grid=param_grid,\n",
    "    cv=5,\n",
    "    scoring='accuracy', # f1, recall, precision\n",
    "    n_jobs=-1,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "grid_search.fit(X_train_vectors, y_train)\n",
    "y_pred = grid_search.predict(X_test_vectors)\n",
    "print_performance(y_test, y_pred)\n",
    "print(\"Best hyperparameters: \", grid_search.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ex5VrGh45sSt"
   },
   "source": [
    "### Tune RF: PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 313
    },
    "id": "UeYMD_T9L51j",
    "outputId": "bfc8c85f-0ca1-4aa7-d42b-37ceda4bf381"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'Cumulative explained variance')"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "pca = PCA(n_components=1500)\n",
    "X_train_pca = pca.fit_transform(X_train_vectors.toarray())\n",
    "X_test_pca = pca.transform(X_test_vectors.toarray())\n",
    "explained_variance = np.cumsum(pca.explained_variance_ratio_)\n",
    "\n",
    "plt.plot(1-explained_variance)\n",
    "plt.axhline(y=0.01, color='red', linestyle='--')\n",
    "plt.title('Scree Plot')\n",
    "plt.xlabel('Number of components')\n",
    "plt.ylabel('Cumulative explained variance')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "nwGkaeHdL8W0",
    "outputId": "1e6b22a0-694a-4b20-e18a-6f8642ed5d1f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k = 1177, Explained variance ratio: 99.009%\n"
     ]
    }
   ],
   "source": [
    "for i, ratio in enumerate(explained_variance):\n",
    "  if ratio > .99:\n",
    "    print(f\"k = {i},\", f\"Explained variance ratio: {ratio*100:.3f}%\")\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "kwSGf7ui9O3F",
    "outputId": "0ce05fa7-5a67-45aa-a9bd-4ebe039470cf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 score:  0.6870563274717\n",
      "Accuracy:  0.7380952380952381\n",
      "MSE:  0.46190476190476193\n",
      "Confusion matrix: \n",
      "[[133   0   0]\n",
      " [ 40  18   0]\n",
      " [ 14   1   4]]\n"
     ]
    }
   ],
   "source": [
    "pca = PCA(n_components=1177)\n",
    "X_train_vectors_pca = pca.fit_transform(X_train_vectors.toarray())\n",
    "X_test_vectors_pca = pca.transform(X_test_vectors.toarray())\n",
    "\n",
    "rf = RandomForestClassifier(max_features='auto', n_estimators=500, random_state=42)\n",
    "rf.fit(X_train_vectors_pca, y_train)\n",
    "y_pred = rf.predict(X_test_vectors_pca)\n",
    "\n",
    "print_performance(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cLA7R0Li9ZH-"
   },
   "source": [
    "To determine the optimal number of components for PCA, we utilized a scree plot and identified a value of k=1177 that explained a variance ratio greater than 99%. However, we did not observe an improvement in the performance of our baseline Random Forest model when incorporating PCA."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lK7mF1BY6hfa"
   },
   "source": [
    "### Turn RF: Feature Selection with RFE\n",
    "\n",
    "Here we use a decision tree-based model as the estimator for the RFE selector, since decision trees and Random Forests have a natural way of ranking the importance of features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "IxgaSwUf6jVv",
    "outputId": "dc5fd43e-b3b8-4244-ef0a-16d3ff98274b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Select 1200 features:\n",
      "F1 score:  0.8225714814725154\n",
      "Accuracy:  0.8380952380952381\n",
      "MSE:  0.2761904761904762\n",
      "Confusion matrix: \n",
      "[[128   5   0]\n",
      " [ 12  43   3]\n",
      " [  8   6   5]]\n",
      "Select 1500 features:\n",
      "F1 score:  0.830991437000125\n",
      "Accuracy:  0.8428571428571429\n",
      "MSE:  0.2714285714285714\n",
      "Confusion matrix: \n",
      "[[128   5   0]\n",
      " [ 14  42   2]\n",
      " [  8   4   7]]\n",
      "Select 1800 features:\n",
      "F1 score:  0.8361097295139847\n",
      "Accuracy:  0.8476190476190476\n",
      "MSE:  0.26666666666666666\n",
      "Confusion matrix: \n",
      "[[128   5   0]\n",
      " [ 13  43   2]\n",
      " [  8   4   7]]\n",
      "Select 2100 features:\n",
      "F1 score:  0.8361097295139847\n",
      "Accuracy:  0.8476190476190476\n",
      "MSE:  0.26666666666666666\n",
      "Confusion matrix: \n",
      "[[128   5   0]\n",
      " [ 13  43   2]\n",
      " [  8   4   7]]\n",
      "Select 2400 features:\n",
      "F1 score:  0.8190083911638684\n",
      "Accuracy:  0.8333333333333334\n",
      "MSE:  0.26666666666666666\n",
      "Confusion matrix: \n",
      "[[128   5   0]\n",
      " [ 15  41   2]\n",
      " [  7   6   6]]\n",
      "Select 2700 features:\n",
      "F1 score:  0.821174611187231\n",
      "Accuracy:  0.8380952380952381\n",
      "MSE:  0.2761904761904762\n",
      "Confusion matrix: \n",
      "[[128   5   0]\n",
      " [ 14  43   1]\n",
      " [  8   6   5]]\n",
      "Select 3000 features:\n",
      "F1 score:  0.821174611187231\n",
      "Accuracy:  0.8380952380952381\n",
      "MSE:  0.2761904761904762\n",
      "Confusion matrix: \n",
      "[[128   5   0]\n",
      " [ 14  43   1]\n",
      " [  8   6   5]]\n",
      "Select 3300 features:\n",
      "F1 score:  0.821174611187231\n",
      "Accuracy:  0.8380952380952381\n",
      "MSE:  0.2761904761904762\n",
      "Confusion matrix: \n",
      "[[128   5   0]\n",
      " [ 14  43   1]\n",
      " [  8   6   5]]\n"
     ]
    }
   ],
   "source": [
    "n = X_train_vectors.shape[1]\n",
    "n_features_range = range(1200, n, 300)\n",
    "selected_dict_rf = dict()\n",
    "for n_features in n_features_range: \n",
    "    estimator = DecisionTreeClassifier(random_state=42)\n",
    "    selector = RFE(estimator, n_features_to_select=n_features)\n",
    "    selector = selector.fit(X_train_vectors, y_train)\n",
    "\n",
    "    selected_feature_indices = selector.get_support(indices=True)\n",
    "    selected_train_rf = X_train_vectors[:,selected_feature_indices]\n",
    "    selected_test_rf = X_test_vectors[:,selected_feature_indices]\n",
    "    selected_dict_rf[n_features] = selected_feature_indices\n",
    "\n",
    "    rf = RandomForestClassifier(max_features='auto', n_estimators=500, random_state=42)\n",
    "    rf.fit(selected_train_rf, y_train)\n",
    "    y_pred = rf.predict(selected_test_rf)\n",
    "    print(f\"Select {n_features} features:\")\n",
    "    print_performance(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "JwyhBqoJV0j7",
    "outputId": "79312c7a-ea3f-4250-b9f6-7660a97934aa"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1883, 1800), (210, 1800))"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "selected_features_rf = selected_dict_rf[1800]\n",
    "X_train_updated_rf = X_train_vectors[:,selected_features_rf]\n",
    "X_test_updated_rf = X_test_vectors[:,selected_features_rf]\n",
    "X_train_updated_rf.shape, X_test_updated_rf.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Unspo_5X9JjF",
    "outputId": "57921b97-ef37-4fcc-ba86-789db7687cd0"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  50.,   51.,   52., ..., 3499., 3500., 3501.])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# np.savetxt('selected_features_rf.txt', selected_features_rf, delimiter='\\t')\n",
    "arr_rf = np.loadtxt('selected_features_rf.txt', delimiter='\\t')\n",
    "arr_rf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KBbC0sUW9hj_"
   },
   "source": [
    "The results of the feature selection analysis demonstrate that the 1800 selected features have significantly improved the performance of the Random Forest (RF) model. The F1 score of the model has increased to 0.836 and the accuracy has improved to 0.848."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "haUKAZtH60Bh"
   },
   "source": [
    "###  Final RF with the whole X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "LrbtSd8Ak7_v",
    "outputId": "10e02556-fee0-4a84-82d8-87c92ca5715b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 score:  0.82145476297931\n",
      "Accuracy:  0.8361204013377926\n",
      "MSE:  0.3129479216435738\n",
      "Confusion matrix: \n",
      "[[1247   42    4]\n",
      " [ 102  399   19]\n",
      " [ 100   76  104]]\n"
     ]
    }
   ],
   "source": [
    "final_rf = RandomForestClassifier(max_features='auto', n_estimators=500, random_state=42)\n",
    "X_updated_rf = X_vectors[:, selected_features_rf]\n",
    "y_pred = cross_val_predict(final_rf, X_updated_rf, y, cv=5)\n",
    "\n",
    "print_performance(y, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "e9L_jIbv-Z7d"
   },
   "source": [
    "To improve the performance of our RF model, we carefully selected 1800 features and optimized the model using them. We then conducted cross-validation on the entire training set, which resulted in an impressive **F1 score of 0.821** and an **accuracy of 0.836**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "skP8w2zIWF2k"
   },
   "source": [
    "# Model 3: SVMs (`Support Vector Machines`)\n",
    "* SVM works by finding the optimal boundary or hyperplane that maximizes the margin between classes in high-dimensional feature space. \n",
    "* It is pretty useful for handling non-linearly separable data through the use of kernel functions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0sYRZYiPDxFE"
   },
   "source": [
    "### Baseline of SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "95YEYCXTWHWy",
    "outputId": "27358967-63d7-4b50-f875-84ca0650af30"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 score:  0.7839776769810899\n",
      "Accuracy:  0.8\n",
      "MSE:  0.35714285714285715\n",
      "Confusion matrix: \n",
      "[[127   5   1]\n",
      " [ 23  34   1]\n",
      " [ 10   2   7]]\n"
     ]
    }
   ],
   "source": [
    "svm = SVC(kernel='linear', random_state=42)\n",
    "svm.fit(X_train_vectors, y_train)\n",
    "y_pred = svm.predict(X_test_vectors)\n",
    "\n",
    "print_performance(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "z0DBLLCMEj_V"
   },
   "source": [
    "### Tune SVM: Grid search best parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "rbW7X55GWHbs",
    "outputId": "a6a8f5d1-1abc-4ebc-85d9-309214640ffb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 score:  0.8104821374120982\n",
      "Accuracy:  0.8238095238095238\n",
      "MSE:  0.3333333333333333\n",
      "Confusion matrix: \n",
      "[[128   3   2]\n",
      " [ 19  38   1]\n",
      " [  9   3   7]]\n",
      "Best hyperparameters:  {'C': 5, 'class_weight': None, 'gamma': 'scale', 'kernel': 'linear'}\n"
     ]
    }
   ],
   "source": [
    "svm = SVC(random_state=42)\n",
    "param_grid = {\n",
    "    'C': [None, 0.1, 0.5, 1, 5, 10, 20],\n",
    "    'kernel': ['linear', 'poly', 'rbf'],\n",
    "    'gamma': ['scale', 'auto'],\n",
    "    'class_weight': [None, 'balanced']\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(estimator=svm, param_grid=param_grid, cv=5)\n",
    "grid_search.fit(X_train_vectors, y_train)\n",
    "y_pred = grid_search.predict(X_test_vectors)\n",
    "\n",
    "print_performance(y_test, y_pred)\n",
    "print(\"Best hyperparameters: \", grid_search.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "x-tk1omXhwOt"
   },
   "source": [
    "### Tune SVM: PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "n-Vmq6xBWHeN",
    "outputId": "37f19621-d288-4f5e-8936-5b707354a0ea"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 score:  0.8127428193499622\n",
      "Accuracy:  0.8285714285714286\n",
      "MSE:  0.3\n",
      "Confusion matrix: \n",
      "[[129   3   1]\n",
      " [ 18  39   1]\n",
      " [  8   5   6]]\n"
     ]
    }
   ],
   "source": [
    "pca = PCA(n_components=1177) # chosen by PCA via screen plot in the chapter of Random Forest\n",
    "X_train_vectors_pca = pca.fit_transform(X_train_vectors.toarray())\n",
    "X_test_vectors_pca = pca.transform(X_test_vectors.toarray())\n",
    "\n",
    "svm = SVC(C=5, gamma='scale', kernel='linear', random_state=42)\n",
    "svm.fit(X_train_vectors_pca, y_train)\n",
    "y_pred = svm.predict(X_test_vectors_pca)\n",
    "\n",
    "print_performance(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "p8c2zfUr_UdT"
   },
   "source": [
    "PCA seem to do enhance its performance a little bit, we decided to stick with the first 1177 features for simplicity's sake. (k=1177 is the boundary for keeping 99% variance)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mMc8qXGWiKdd"
   },
   "source": [
    "### Turn SVM: Feature Selection with RFE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "EkdN4TXCWHgf",
    "outputId": "72706cd9-04d2-4c8b-8ea5-452f3e8a3d2a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Select 400 features:\n",
      "F1 score:  0.780184171090599\n",
      "Accuracy:  0.7952380952380952\n",
      "MSE:  0.319047619047619\n",
      "Confusion matrix: \n",
      "[[126   6   1]\n",
      " [ 22  34   2]\n",
      " [  7   5   7]]\n",
      "Select 700 features:\n",
      "F1 score:  0.8060262811436519\n",
      "Accuracy:  0.819047619047619\n",
      "MSE:  0.26666666666666666\n",
      "Confusion matrix: \n",
      "[[127   5   1]\n",
      " [ 19  38   1]\n",
      " [  5   7   7]]\n",
      "Select 1000 features:\n",
      "F1 score:  0.8104321548580002\n",
      "Accuracy:  0.8238095238095238\n",
      "MSE:  0.319047619047619\n",
      "Confusion matrix: \n",
      "[[128   3   2]\n",
      " [ 19  38   1]\n",
      " [  8   4   7]]\n"
     ]
    }
   ],
   "source": [
    "n_features_range = range(400, 1200, 300)\n",
    "selected_dict_svm = dict()\n",
    "for n_features in n_features_range: \n",
    "    estimator = SVC(C=5, gamma='scale', kernel='linear', random_state=42)\n",
    "    selector = RFE(estimator, n_features_to_select=n_features)\n",
    "    selector = selector.fit(X_train_vectors_pca, y_train)\n",
    "\n",
    "    selected_feature_indices = selector.get_support(indices=True)\n",
    "    selected_train_svm = X_train_vectors_pca[:,selected_feature_indices]\n",
    "    selected_test_svm = X_test_vectors_pca[:,selected_feature_indices]\n",
    "    selected_dict_svm[n_features] = selected_feature_indices\n",
    "\n",
    "    svm = SVC(C=5, gamma='scale', kernel='linear', random_state=42)\n",
    "    svm.fit(selected_train_svm, y_train)\n",
    "    y_pred = svm.predict(selected_test_svm)\n",
    "    print(f\"Select {n_features} features:\")\n",
    "    print_performance(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9ZngDTcf_lMd"
   },
   "source": [
    "After applying PCA, the number of features in the dataset is reduced to a smaller set of principal components that explain most of the variance in the data. Therefore, it is not necessary to reduce the number of features further, as this would result in a loss of information."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6C367aLkiiH7"
   },
   "source": [
    "###  Final SVM with the whole X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "yEgLoA0rWHjG",
    "outputId": "183ffdfc-e182-4b9b-b4d0-40a569a5154a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 score:  0.8253527203080023\n",
      "Accuracy:  0.8346870520783565\n",
      "MSE:  0.3129479216435738\n",
      "Confusion matrix: \n",
      "[[1240   35   18]\n",
      " [ 122  370   28]\n",
      " [  85   58  137]]\n"
     ]
    }
   ],
   "source": [
    "pca = PCA(n_components=1177)\n",
    "X_vectors_pca_svm = pca.fit_transform(X_vectors.toarray())\n",
    "\n",
    "final_svm = SVC(C=5, gamma='scale', kernel='linear', random_state=42)\n",
    "y_pred = cross_val_predict(final_svm, X_vectors_pca_svm, y, cv=5)\n",
    "\n",
    "print_performance(y, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "d_YDMLWw_0xm"
   },
   "source": [
    "Our final SVM model, optimized with PCA method and tuned hyperparameters (C=5, gamma='scale', kernel='linear'), yielded impressive results on the entire training set. The combined approach resulted in an **F1 score of 0.825** and an **accuracy of 0.835**, indicating that our model is well-suited for the given dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Cgq7nQLgGLiF"
   },
   "source": [
    "# Model 4: Logistic Regression\n",
    "* Logistic Regression is commonly used for binary classification problems. \n",
    "* It estimates the parameters of a logistic function to map the input features to the predicted probabilities, and it can be extended to handle multi-class classification problems through techniques such as one-vs-all or softmax regression."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HY2Bvdg0tnCz"
   },
   "source": [
    "### Baseline of LR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "tjPqa_0GGNT3",
    "outputId": "eff7bfac-8d84-4777-d753-6c9ebdde6d85"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 score:  0.7352717652717653\n",
      "Accuracy:  0.7714285714285715\n",
      "MSE:  0.42857142857142855\n",
      "Confusion matrix: \n",
      "[[131   2   0]\n",
      " [ 30  28   0]\n",
      " [ 14   2   3]]\n"
     ]
    }
   ],
   "source": [
    "lr = LogisticRegression(multi_class='multinomial')\n",
    "lr.fit(X_train_vectors, y_train)\n",
    "y_pred = lr.predict(X_test_vectors)\n",
    "\n",
    "print_performance(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_EG1pOuGtydW"
   },
   "source": [
    "### Tune LR: Grid search best parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "acB9ocITGNWD",
    "outputId": "327a35f5-2233-44d3-8b93-e296e835ae0f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 score:  0.812218986198578\n",
      "Accuracy:  0.8285714285714286\n",
      "MSE:  0.3142857142857143\n",
      "Confusion matrix: \n",
      "[[131   2   0]\n",
      " [ 22  36   0]\n",
      " [ 10   2   7]]\n",
      "Best hyperparameters:  {'C': 5, 'penalty': 'l2', 'solver': 'lbfgs'}\n"
     ]
    }
   ],
   "source": [
    "lr = LogisticRegression(multi_class='multinomial')\n",
    "param_grid = {\n",
    "    'C': [None, 0.1, 0.5, 1, 5, 10],\n",
    "    'penalty': [None, 'l1', 'l2'],\n",
    "    'solver': [None, 'lbfgs', 'liblinear', 'saga']\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(estimator=lr, param_grid=param_grid, cv=5)\n",
    "grid_search.fit(X_train_vectors, y_train)\n",
    "y_pred = grid_search.predict(X_test_vectors)\n",
    "\n",
    "print_performance(y_test, y_pred)\n",
    "print(\"Best hyperparameters: \", grid_search.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Hkv5MN_qvyN-"
   },
   "source": [
    "### Tune LR: PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "SFHQonduGNYX",
    "outputId": "4d6485ed-4bfa-43d7-abc6-59beeeb328dc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 score:  0.7979024490888897\n",
      "Accuracy:  0.8142857142857143\n",
      "MSE:  0.32857142857142857\n",
      "Confusion matrix: \n",
      "[[129   4   0]\n",
      " [ 23  35   0]\n",
      " [ 10   2   7]]\n"
     ]
    }
   ],
   "source": [
    "pca = PCA(n_components=1177) # chosen by PCA via screen plot in the chapter of Random Forest\n",
    "X_train_vectors_pca = pca.fit_transform(X_train_vectors.toarray())\n",
    "X_test_vectors_pca = pca.transform(X_test_vectors.toarray())\n",
    "\n",
    "lr = LogisticRegression(C=5, penalty='l2', solver='lbfgs', random_state=42)\n",
    "lr.fit(X_train_vectors_pca, y_train)\n",
    "y_pred = lr.predict(X_test_vectors_pca)\n",
    "\n",
    "print_performance(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "j7yCI0qnBzs3"
   },
   "source": [
    "Based on our analysis, it seems that PCA does not provide any benefits for our logistic regression model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QH39vUk2w6HI"
   },
   "source": [
    "### Turn LR: Feature Selection with RFE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Y7ufQRypw6HI",
    "outputId": "b7c85984-4ada-439a-f04c-d257262f9e02"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Select 400 features:\n",
      "F1 score:  0.7437640825928378\n",
      "Accuracy:  0.7714285714285715\n",
      "MSE:  0.44285714285714284\n",
      "Confusion matrix: \n",
      "[[127   5   1]\n",
      " [ 24  32   2]\n",
      " [ 14   2   3]]\n",
      "Select 700 features:\n",
      "F1 score:  0.7802698183650564\n",
      "Accuracy:  0.8\n",
      "MSE:  0.38571428571428573\n",
      "Confusion matrix: \n",
      "[[128   4   1]\n",
      " [ 21  35   2]\n",
      " [ 12   2   5]]\n",
      "Select 1000 features:\n",
      "F1 score:  0.7956826421717462\n",
      "Accuracy:  0.8142857142857143\n",
      "MSE:  0.34285714285714286\n",
      "Confusion matrix: \n",
      "[[130   3   0]\n",
      " [ 21  35   2]\n",
      " [ 11   2   6]]\n"
     ]
    }
   ],
   "source": [
    "n_features_range = range(400, 1200, 300)\n",
    "selected_dict_lr = dict()\n",
    "for n_features in n_features_range: \n",
    "    estimator = LogisticRegression(random_state=42)\n",
    "    selector = RFE(estimator, n_features_to_select=n_features)\n",
    "    selector = selector.fit(X_train_vectors, y_train)\n",
    "\n",
    "    selected_feature_indices = selector.get_support(indices=True)\n",
    "    selected_train_lr = X_train_vectors[:,selected_feature_indices]\n",
    "    selected_test_lr = X_test_vectors[:,selected_feature_indices]\n",
    "    selected_dict_lr[n_features] = selected_feature_indices\n",
    "\n",
    "    lr = LogisticRegression(C=5, penalty='l2', solver='lbfgs', random_state=42)\n",
    "    lr.fit(selected_train_lr, y_train)\n",
    "    y_pred = lr.predict(selected_test_lr)\n",
    "    print(f\"Select {n_features} features:\")\n",
    "    print_performance(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7ICDwQ98CAp1"
   },
   "source": [
    "For the sake of simplicity, we would not keep to use RFE in LR as well."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TCLJEVJFv4no"
   },
   "source": [
    "### Final LR with the whole X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jI4KB6v-v6By",
    "outputId": "5805f2b3-e447-4a27-f9ae-fd9449fe7f4f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 score:  0.8208211939649664\n",
      "Accuracy:  0.8351648351648352\n",
      "MSE:  0.32823698041089344\n",
      "Confusion matrix: \n",
      "[[1271   17    5]\n",
      " [ 149  357   14]\n",
      " [ 109   51  120]]\n"
     ]
    }
   ],
   "source": [
    "final_lr = LogisticRegression(multi_class='multinomial', C=5, penalty='l2', \n",
    "                             solver='lbfgs', random_state=42)\n",
    "y_pred = cross_val_predict(final_lr, X_vectors, y, cv=5)\n",
    "\n",
    "print_performance(y, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IUZSXyARCE8K"
   },
   "source": [
    "We have optimized the LR model with hyperparameters C=5, penalty='l2', and solver='lbfgs'. The resulting **F1 score was 0.821**, and the **accuracy was 0.835**, indicating that the model is performing well on the given dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "T1dHFkBNXDfb"
   },
   "source": [
    "# Model 5: AdaBoost (`Adaptive Boosting`)\n",
    "\n",
    "*  AdaBoost works by combining multiple weak classifiers into a strong classifier through iterative training. \n",
    "* In each iteration, the algorithm assigns higher weights to the incorrectly classified samples and lower weights to the correctly classified ones, thus focusing on the more difficult samples in subsequent iterations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yzrrzDEW5D92"
   },
   "source": [
    "### Baseline of Ada"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "P-J83tSu415m",
    "outputId": "fc1642cb-f3de-4938-8181-f2a2a2809067"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 score:  0.7936480386547142\n",
      "Accuracy:  0.8095238095238095\n",
      "MSE:  0.3476190476190476\n",
      "Confusion matrix: \n",
      "[[126   5   2]\n",
      " [ 17  39   2]\n",
      " [  9   5   5]]\n"
     ]
    }
   ],
   "source": [
    "dtc = DecisionTreeClassifier(max_depth=2)\n",
    "ada = AdaBoostClassifier(base_estimator=dtc, random_state=42)\n",
    "ada.fit(X_train_vectors, y_train)\n",
    "y_pred = ada.predict(X_test_vectors)\n",
    "\n",
    "print_performance(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2N33fmUM3gVK"
   },
   "source": [
    "### Tune Ada: Grid search best parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "pl1N3U3NXC5G",
    "outputId": "2c2246bc-7bb9-4d3a-df2c-3a40b9482db2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 score:  0.827559758655165\n",
      "Accuracy:  0.8380952380952381\n",
      "MSE:  0.24761904761904763\n",
      "Confusion matrix: \n",
      "[[130   3   0]\n",
      " [ 14  38   6]\n",
      " [  6   5   8]]\n",
      "Best hyperparameters:  {'learning_rate': 0.1, 'n_estimators': 200}\n"
     ]
    }
   ],
   "source": [
    "max_depth_list = [10] # already tested [None, 5, 10]\n",
    "for max_depth in max_depth_list:\n",
    "    dtc = DecisionTreeClassifier(max_depth=max_depth) \n",
    "    ada = AdaBoostClassifier(base_estimator=dtc, random_state=42)\n",
    "    param_grid = {'learning_rate': [0.01, 0.1, 0.5, 1],\n",
    "                  'n_estimators': [50, 100, 200, 500]}\n",
    "\n",
    "    grid_search = GridSearchCV(estimator=ada, param_grid=param_grid, cv=5)\n",
    "    grid_search.fit(X_train_vectors, y_train)\n",
    "    y_pred = grid_search.predict(X_test_vectors)\n",
    "    \n",
    "    print_performance(y_test, y_pred)\n",
    "    print(\"Best hyperparameters: \", grid_search.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VLhnU5oHDcIM"
   },
   "source": [
    "After comparing the results, we found that using a learning rate of 0.1 and 200 estimators, along with a maximum decision tree depth of 10, yielded the best performance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nqAVxh1dPtNx"
   },
   "source": [
    "### Tune Ada: PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "n4NoanUKPtNy",
    "outputId": "ff3040b4-df19-481a-d22d-36edaddf5010"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 score:  0.812344214106382\n",
      "Accuracy:  0.8238095238095238\n",
      "MSE:  0.2904761904761905\n",
      "Confusion matrix: \n",
      "[[126   6   1]\n",
      " [ 16  40   2]\n",
      " [  7   5   7]]\n"
     ]
    }
   ],
   "source": [
    "pca = PCA(n_components=1177) # chosen by PCA via screen plot in the chapter of Random Forest\n",
    "X_train_vectors_pca = pca.fit_transform(X_train_vectors.toarray())\n",
    "X_test_vectors_pca = pca.transform(X_test_vectors.toarray())\n",
    "\n",
    "dtc = DecisionTreeClassifier(max_depth=10)\n",
    "ada = AdaBoostClassifier(base_estimator=dtc, learning_rate=.1, n_estimators=200, random_state=42)\n",
    "ada.fit(X_train_vectors_pca, y_train)\n",
    "y_pred = ada.predict(X_test_vectors_pca)\n",
    "\n",
    "print_performance(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PF6tTJy5Dvo3"
   },
   "source": [
    "PCA does not seem to improve the performance of the AdaBoost algorithm significantly."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sNjtBX-zPhmy"
   },
   "source": [
    "### Turn Ada: Feature Selection with RFE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2_AivNZVPhmy",
    "outputId": "6361a987-efbb-482a-c17e-767ea42c997f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Select 900 features:\n",
      "F1 score:  0.7664506569751188\n",
      "Accuracy:  0.7857142857142857\n",
      "MSE:  0.34285714285714286\n",
      "Confusion matrix: \n",
      "[[127   5   1]\n",
      " [ 24  32   2]\n",
      " [  8   5   6]]\n"
     ]
    }
   ],
   "source": [
    "n_features_range = [900] # already tested range(400, 1200, 300)\n",
    "selected_dict_ada = dict()\n",
    "for n_features in n_features_range: \n",
    "    estimator = LogisticRegression()\n",
    "    selector = RFE(estimator, n_features_to_select=n_features)\n",
    "    selector = selector.fit(X_train_vectors_pca, y_train)\n",
    "\n",
    "    selected_feature_indices = selector.get_support(indices=True)\n",
    "    selected_train_ada = X_train_vectors_pca[:,selected_feature_indices]\n",
    "    selected_test_ada = X_test_vectors_pca[:,selected_feature_indices]\n",
    "    selected_dict_ada[n_features] = selected_feature_indices\n",
    "\n",
    "    dtc = DecisionTreeClassifier(max_depth=10)\n",
    "    ada = AdaBoostClassifier(base_estimator=dtc, learning_rate=.1, n_estimators=200, random_state=42)\n",
    "    ada.fit(selected_train_ada, y_train)\n",
    "    y_pred = ada.predict(selected_test_ada)\n",
    "    print(f\"Select {n_features} features:\")\n",
    "    print_performance(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "n1Tl0LDnD45K"
   },
   "source": [
    "Same, the other feature selection method does not work for Ada as well."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PHz1NqF9PGeQ"
   },
   "source": [
    "### Final Ada with the whole X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Vv-S3BwcakZN",
    "outputId": "db2bcafa-c2cc-4fe8-d74b-e36957af202a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 score:  0.8164610224165573\n",
      "Accuracy:  0.8265647396082179\n",
      "MSE:  0.3110367892976589\n",
      "Confusion matrix: \n",
      "[[1228   48   17]\n",
      " [ 103  382   35]\n",
      " [  79   81  120]]\n"
     ]
    }
   ],
   "source": [
    "dtc = DecisionTreeClassifier(max_depth=10, random_state=42)\n",
    "final_ada = AdaBoostClassifier(base_estimator=dtc, learning_rate=.1, n_estimators=200, random_state=42)\n",
    "y_pred = cross_val_predict(final_ada, X_vectors, y, cv=5)\n",
    "\n",
    "print_performance(y, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ozv5l6-QD-oh"
   },
   "source": [
    "We used the optimal hyperparameters obtained through grid searching to update the AdaBoost model, neither PCA or RFE can help to improve its performance. The model achieved an **F1 score of 0.816** and **accuracy of 0.827** on the whole training set with 5-fold cross-validation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bOXyRZfHak5w"
   },
   "source": [
    "# Model 6: NLPaug + ML models\n",
    "* [NLPaug](https://nlpaug.readthedocs.io/en/latest/augmenter/augmenter.html) is a data augmentation technique for NLP that enhances the training data by generating synthetic examples. **Although it is not a ML model, we combine it with other classification models to create a comprehensive ML model. Thus, we refer to the combination of NLPaug and any other models as a ML model for the sake of simplicity.**\n",
    "* It provides a wide range of data augmentation techniques for natural language processing tasks, which can help improve the performance of machine learning models by increasing the amount of training data available, enhancing the diversity of the data, and reducing overfitting. \n",
    "* NLPaug supports various augmentation operations, such as word and character-level replacements, synonym replacement, OCR-like augmentations, and more."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "MgItLsfTBFf-"
   },
   "outputs": [],
   "source": [
    "# !pip install nlpaug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "GPefErwkIIoA"
   },
   "outputs": [],
   "source": [
    "import nlpaug.augmenter.char as nac\n",
    "import nlpaug.augmenter.word as naw\n",
    "import nlpaug.flow as naf\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ed4WOJskokFz"
   },
   "source": [
    "### Build an augmentation pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-hjUJa1BGgD_"
   },
   "source": [
    "Here we use two augmentation technique in pipeline, then train different classifiers on the augmented data:\n",
    "\n",
    "* KeyboardAug is a type of augmentation that simulates keyboard typing errors and is used to increase the robustness of text data by introducing variations. This augmentation randomly adds, deletes, or replaces characters in the text.\n",
    "\n",
    "* SynonymAug, on the other hand, replaces words in the text with their synonyms to increase the diversity of the data and improve the model's ability to generalize to unseen data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "M1TKgAhAaqCD",
    "outputId": "d1e0adef-dcb2-4904-9e63-ce261b33fba9"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /root/nltk_data...\n",
      "[nltk_data]   Unzipping taggers/averaged_perceptron_tagger.zip.\n"
     ]
    }
   ],
   "source": [
    "# Create an aug object for character-level augmentation\n",
    "aug1 = nac.KeyboardAug()\n",
    "aug2 = naw.SynonymAug()\n",
    "\n",
    "# Create an augmentation pipeline\n",
    "aug_pipeline = naf.Sequential([aug1, aug2])\n",
    "\n",
    "# Augment the training data\n",
    "X_train_augmented = []\n",
    "y_train_augmented = []\n",
    "\n",
    "for text, label in zip(X_train, y_train):\n",
    "    for _ in range(5): # Augment each sentence by 5 times\n",
    "        augmented_text = aug_pipeline.augment(text)\n",
    "        if augmented_text:\n",
    "          X_train_augmented.append(augmented_text[0])\n",
    "        else: X_train_augmented.append('')\n",
    "        y_train_augmented.append(label)\n",
    "\n",
    "# Combine the original data with the augmented data\n",
    "X_train_combined = pd.concat([X_train, pd.Series(X_train_augmented)])\n",
    "y_train_combined = pd.concat([y_train, pd.Series(y_train_augmented)])\n",
    "\n",
    "# Vectorize the text data\n",
    "vectorizer = CountVectorizer()\n",
    "X_train_vectorized = vectorizer.fit_transform(X_train_combined)\n",
    "X_test_vectorized = vectorizer.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kGzEahaWouzf"
   },
   "source": [
    "### Combine with ML models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "j4Ch206KgCwa"
   },
   "source": [
    "Next, we will combine each model's \"best fit format\" with our augmentation pipeline to compare the combinations' performance. By doing so, we can accurately compare their performance and select the most suitable model for our specific use case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "q2V7eD9xFGUy",
    "outputId": "d0c380b8-6229-4a9b-9093-ac30ea4f920c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 score:  0.7778923751886981\n",
      "Accuracy:  0.7952380952380952\n",
      "MSE:  0.319047619047619\n",
      "Confusion matrix: \n",
      "[[129   4   0]\n",
      " [ 22  30   6]\n",
      " [  8   3   8]]\n"
     ]
    }
   ],
   "source": [
    "# Train a Naive Bayes classifier on the augmented data\n",
    "classifier = MultinomialNB(alpha=1.4, fit_prior=False)\n",
    "classifier.fit(X_train_vectorized, y_train_combined)\n",
    "y_pred = classifier.predict(X_test_vectorized)\n",
    "\n",
    "print_performance(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "h61YMfxSFIiY",
    "outputId": "2e1f73f9-02bc-458e-ffd1-93dfc5abc616"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 score:  0.815963249572501\n",
      "Accuracy:  0.819047619047619\n",
      "MSE:  0.23809523809523808\n",
      "Confusion matrix: \n",
      "[[119  12   2]\n",
      " [ 11  45   2]\n",
      " [  2   9   8]]\n"
     ]
    }
   ],
   "source": [
    "# Train a Random Forest classifier on the augmented data\n",
    "classifier = RandomForestClassifier(max_features='auto', n_estimators=500, random_state=42)\n",
    "classifier.fit(X_train_vectorized, y_train_combined)\n",
    "y_pred = classifier.predict(X_test_vectorized)\n",
    "\n",
    "print_performance(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "IdQY8CJ2FeYu",
    "outputId": "fcdb01c7-fecd-4091-c83b-67a285e8a8d4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 score:  0.8411714471363595\n",
      "Accuracy:  0.8428571428571429\n",
      "MSE:  0.2571428571428571\n",
      "Confusion matrix: \n",
      "[[121   8   4]\n",
      " [ 13  44   1]\n",
      " [  3   4  12]]\n"
     ]
    }
   ],
   "source": [
    "# Train a SVM classifier on the augmented data\n",
    "classifier = SVC(C=5, gamma='scale', kernel='linear', random_state=42)\n",
    "classifier.fit(X_train_vectorized, y_train_combined)\n",
    "y_pred = classifier.predict(X_test_vectorized)\n",
    "\n",
    "print_performance(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4feyRTPVFghH",
    "outputId": "7218e5fc-e874-4f24-c3a5-7b2ad87e8642"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 score:  0.8504236090571495\n",
      "Accuracy:  0.8523809523809524\n",
      "MSE:  0.20476190476190476\n",
      "Confusion matrix: \n",
      "[[123   8   2]\n",
      " [ 12  44   2]\n",
      " [  2   5  12]]\n"
     ]
    }
   ],
   "source": [
    "# Train a Logistic regression classifier on the augmented data\n",
    "classifier = LogisticRegression(multi_class='multinomial', C=5, penalty='l2', \n",
    "                                solver='lbfgs', random_state=42)\n",
    "classifier.fit(X_train_vectorized, y_train_combined)\n",
    "y_pred = classifier.predict(X_test_vectorized)\n",
    "\n",
    "print_performance(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Ij2wnBWpFixZ",
    "outputId": "a1e73598-bc0a-4d9e-940b-64c394ea0f2c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 score:  0.8234498801963385\n",
      "Accuracy:  0.8238095238095238\n",
      "MSE:  0.2904761904761905\n",
      "Confusion matrix: \n",
      "[[120   8   5]\n",
      " [ 11  43   4]\n",
      " [  3   6  10]]\n"
     ]
    }
   ],
   "source": [
    "# Train a AdaBoost classifier on the augmented data\n",
    "dtc = DecisionTreeClassifier(max_depth=10, random_state=42)\n",
    "classifier = AdaBoostClassifier(base_estimator=dtc, learning_rate=.1, \n",
    "                                n_estimators=200, random_state=42)\n",
    "classifier.fit(X_train_vectorized, y_train_combined)\n",
    "y_pred = classifier.predict(X_test_vectorized)\n",
    "\n",
    "print_performance(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sFam3EEZGux2"
   },
   "source": [
    "Based on the performance of the five classification models on the augmented data, we have decided to use the optimized Logistic Regression model to combine with the augmentation technique as the final one. This model achieved an **F1 score of 0.850** and an **accuracy of 0.852**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3nEhDxdWU-rP"
   },
   "source": [
    "# Application: Ensemble Learning with Combined Votes of 6 Text Classification Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "m56pIey-Z6y_"
   },
   "source": [
    "### Ensemble classification of labeled data using multiple models\n",
    "\n",
    "I combined the six text classification models into a single function, trained it on the training set, and evaluated its performance on the test set. The ensemble model uses the mode of votes from these models to classify text. The results were impressive, achieving an **F1 score of 0.851** and an **accuracy of 0.862**. These scores outperformed any single model used before."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fADjVqdkdW1Q"
   },
   "outputs": [],
   "source": [
    "def merge_models(X_train_vectors, X_new_vectors, X_train, X_new, y_train,\n",
    "                 selected_features_nb, selected_features_rf):\n",
    "    # final naive bayes\n",
    "    X_new_updated_nb = X_new_vectors[:, selected_features_nb]\n",
    "    final_nb = MultinomialNB(alpha=1.4, fit_prior=False)\n",
    "    X_updated_nb = X_train_vectors[:, selected_features_nb]\n",
    "    final_nb.fit(X_updated_nb, y_train)\n",
    "    y_pred_nb = final_nb.predict(X_new_updated_nb)\n",
    "\n",
    "    # final random forest\n",
    "    X_new_updated_rf = X_new_vectors[:, selected_features_rf]\n",
    "    final_rf = RandomForestClassifier(max_features='auto', n_estimators=500, random_state=42)\n",
    "    X_updated_rf = X_train_vectors[:, selected_features_rf]\n",
    "    final_rf.fit(X_updated_rf, y_train)\n",
    "    y_pred_rf = final_rf.predict(X_new_updated_rf)\n",
    "\n",
    "    # final SVM\n",
    "    pca = PCA(n_components=1177)\n",
    "    X_train_vectors_pca_svm = pca.fit_transform(X_train_vectors.toarray())\n",
    "    X_new_updated_pca_svm = pca.transform(X_new_vectors.toarray())\n",
    "    final_svm = SVC(C=5, gamma='scale', kernel='linear', random_state=42)\n",
    "    final_svm.fit(X_train_vectors_pca_svm, y_train)\n",
    "    y_pred_svm = final_svm.predict(X_new_updated_pca_svm)\n",
    "\n",
    "    # final Logistic Regression\n",
    "    final_lr = LogisticRegression(multi_class='multinomial', C=5, penalty='l2', \n",
    "                                  solver='lbfgs', random_state=42)\n",
    "    final_lr.fit(X_train_vectors, y_train)\n",
    "    y_pred_lr = final_lr.predict(X_new_vectors)\n",
    "\n",
    "    # final AdaBoost\n",
    "    dtc = DecisionTreeClassifier(max_depth=10)\n",
    "    final_ada = AdaBoostClassifier(base_estimator=dtc, learning_rate=.1, \n",
    "                                   n_estimators=200, random_state=42)\n",
    "    final_ada.fit(X_train_vectors, y_train)\n",
    "    y_pred_ada = final_ada.predict(X_new_vectors)\n",
    "\n",
    "    # augmentation with LR\n",
    "    aug1 = nac.KeyboardAug()\n",
    "    aug2 = naw.SynonymAug()\n",
    "    aug_pipeline = naf.Sequential([aug1, aug2])\n",
    "\n",
    "    X_train_augmented = []\n",
    "    y_train_augmented = []\n",
    "    for text, label in zip(X_train, y_train):\n",
    "        for _ in range(5): \n",
    "            augmented_text = aug_pipeline.augment(text)\n",
    "            if augmented_text:\n",
    "              X_train_augmented.append(augmented_text[0])\n",
    "            else: X_train_augmented.append('')\n",
    "            y_train_augmented.append(label)\n",
    "    X_train_combined = pd.concat([X_train, pd.Series(X_train_augmented)])\n",
    "    y_train_combined = pd.concat([y_train, pd.Series(y_train_augmented)])\n",
    "\n",
    "    vectorizer = CountVectorizer()\n",
    "    X_train_vectorized = vectorizer.fit_transform(X_train_combined)\n",
    "    X_test_vectorized = vectorizer.transform(X_new)\n",
    "    classifier = LogisticRegression(multi_class='multinomial', C=5, penalty='l2', \n",
    "                                    solver='lbfgs', random_state=42)\n",
    "    classifier.fit(X_train_vectorized, y_train_combined)\n",
    "    y_pred_aug = classifier.predict(X_test_vectorized)\n",
    "\n",
    "    return y_pred_nb, y_pred_rf, y_pred_svm, y_pred_lr, y_pred_ada, y_pred_aug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Ps1MIotqfJMH"
   },
   "outputs": [],
   "source": [
    "selected_features_nb = np.loadtxt('selected_features_nb.txt', delimiter='\\t')\n",
    "selected_features_rf = np.loadtxt('selected_features_rf.txt', delimiter='\\t')\n",
    "y_pred_nb, y_pred_rf, y_pred_svm, y_pred_lr, y_pred_ada, y_pred_aug = merge_models(X_train_vectors, X_test_vectors, \n",
    "                                                                                   X_train, X_test, y_train,\n",
    "                                                                                   selected_features_nb, selected_features_rf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "x2Ks_sJTj1rB",
    "outputId": "a4ed685c-d019-4e2b-d15b-8d25573f8669"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(210, 210, 210, 210, 210, 210)"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(y_pred_nb), len(y_pred_rf), len(y_pred_svm), len(y_pred_lr), len(y_pred_ada), len(y_pred_aug)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vugF-fL8hS7Y",
    "outputId": "316402b5-a415-4b12-981d-d82d20f728fe"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "210"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target = []\n",
    "for i in range(len(y_pred_nb)):\n",
    "    temp = Counter([y_pred_nb[i], y_pred_rf[i], y_pred_svm[i], y_pred_lr[i], y_pred_ada[i], y_pred_aug[i]]).most_common(1)\n",
    "    target.append(temp)\n",
    "len(target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "uSVEoWsao_E-",
    "outputId": "ee900670-84af-488f-aaee-d975979a4a05"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 score:  0.8506447453255964\n",
      "Accuracy:  0.861904761904762\n",
      "MSE:  0.26666666666666666\n",
      "Confusion matrix: \n",
      "[[129   4   0]\n",
      " [ 11  45   2]\n",
      " [  9   3   7]]\n"
     ]
    }
   ],
   "source": [
    "y_pred = [i[0][0] for i in target]\n",
    "print_performance(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "misZB55wo45m"
   },
   "source": [
    "### Predicting unlabeled data with the ensemble model\n",
    "\n",
    "Next, we will utilize the ensemble model to predict the categories of an unlabeled subset, which is a slice of the unlabeled dataset with indices ranging from 40,000 to 80,000."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 531
    },
    "id": "h72cn0i7Wh4I",
    "outputId": "9c126b29-4f80-4bad-af86-3a46e3914e41"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "  <div id=\"df-74ea8017-1e7d-411f-b316-bcc0abd97664\">\n",
       "    <div class=\"colab-df-container\">\n",
       "      <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>index</th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>created_datetime</th>\n",
       "      <th>content</th>\n",
       "      <th>author_id</th>\n",
       "      <th>place_id</th>\n",
       "      <th>location</th>\n",
       "      <th>longitude</th>\n",
       "      <th>latitude</th>\n",
       "      <th>county</th>\n",
       "      <th>tokenized_tweets</th>\n",
       "      <th>tokenized</th>\n",
       "      <th>merged</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.000014e+17</td>\n",
       "      <td>2011-08-07</td>\n",
       "      <td>Bear Grylls just bit a trout's head off!</td>\n",
       "      <td>18003609.0</td>\n",
       "      <td>fbd6d2f5a4e4a15e</td>\n",
       "      <td>California, USA</td>\n",
       "      <td>-120.645800</td>\n",
       "      <td>35.247868</td>\n",
       "      <td>SAN LUIS OBISPO</td>\n",
       "      <td>([bear, grylls, bit, trout, head], bear grylls...</td>\n",
       "      <td>[bear, grylls, bit, trout, head]</td>\n",
       "      <td>bear grylls bit trout head</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.000016e+18</td>\n",
       "      <td>2018-05-25</td>\n",
       "      <td>@StacyGSG love the Jets t-shirt on the bear</td>\n",
       "      <td>596144748.0</td>\n",
       "      <td>a592bd6ceb1319f7</td>\n",
       "      <td>San Diego, CA</td>\n",
       "      <td>-117.109730</td>\n",
       "      <td>32.801037</td>\n",
       "      <td>SAN DIEGO</td>\n",
       "      <td>([love, jet, shirt, bear], love jet shirt bear)</td>\n",
       "      <td>[love, jet, shirt, bear]</td>\n",
       "      <td>love jet shirt bear</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1.000017e+18</td>\n",
       "      <td>2018-05-25</td>\n",
       "      <td>Kid: what is this this is boring. I wish it wa...</td>\n",
       "      <td>31197211.0</td>\n",
       "      <td>0c2e6999105f8070</td>\n",
       "      <td>Anaheim, CA</td>\n",
       "      <td>-117.829060</td>\n",
       "      <td>33.810070</td>\n",
       "      <td>ORANGE</td>\n",
       "      <td>([kid, boring, wish, mickey, mouse, club, pare...</td>\n",
       "      <td>[kid, boring, wish, mickey, mouse, club, paren...</td>\n",
       "      <td>kid boring wish mickey mouse club parent quiet...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>1.000040e+17</td>\n",
       "      <td>2011-08-07</td>\n",
       "      <td>Making hubby jealous (@ Big Bear Valley Sports...</td>\n",
       "      <td>19245601.0</td>\n",
       "      <td>17fe6350a3570c69</td>\n",
       "      <td>Big Bear Lake, CA</td>\n",
       "      <td>-116.866684</td>\n",
       "      <td>34.259740</td>\n",
       "      <td>SAN BERNARDINO</td>\n",
       "      <td>([making, hubby, jealous, big, bear, valley, s...</td>\n",
       "      <td>[making, hubby, jealous, big, bear, valley, sp...</td>\n",
       "      <td>making hubby jealous big bear valley sportsman...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>1.000055e+18</td>\n",
       "      <td>2018-05-25</td>\n",
       "      <td>Yep. Only one Bear. https://t.co/WfUOioWGmd</td>\n",
       "      <td>415006664.0</td>\n",
       "      <td>fbd6d2f5a4e4a15e</td>\n",
       "      <td>California, USA</td>\n",
       "      <td>-119.311030</td>\n",
       "      <td>37.250366</td>\n",
       "      <td>MADERA</td>\n",
       "      <td>([yep, one, bear], yep one bear)</td>\n",
       "      <td>[yep, one, bear]</td>\n",
       "      <td>yep one bear</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-74ea8017-1e7d-411f-b316-bcc0abd97664')\"\n",
       "              title=\"Convert this dataframe to an interactive table.\"\n",
       "              style=\"display:none;\">\n",
       "        \n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "       width=\"24px\">\n",
       "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
       "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
       "  </svg>\n",
       "      </button>\n",
       "      \n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      flex-wrap:wrap;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "      <script>\n",
       "        const buttonEl =\n",
       "          document.querySelector('#df-74ea8017-1e7d-411f-b316-bcc0abd97664 button.colab-df-convert');\n",
       "        buttonEl.style.display =\n",
       "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "        async function convertToInteractive(key) {\n",
       "          const element = document.querySelector('#df-74ea8017-1e7d-411f-b316-bcc0abd97664');\n",
       "          const dataTable =\n",
       "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                     [key], {});\n",
       "          if (!dataTable) return;\n",
       "\n",
       "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "            + ' to learn more about interactive tables.';\n",
       "          element.innerHTML = '';\n",
       "          dataTable['output_type'] = 'display_data';\n",
       "          await google.colab.output.renderOutput(dataTable, element);\n",
       "          const docLink = document.createElement('div');\n",
       "          docLink.innerHTML = docLinkHtml;\n",
       "          element.appendChild(docLink);\n",
       "        }\n",
       "      </script>\n",
       "    </div>\n",
       "  </div>\n",
       "  "
      ],
      "text/plain": [
       "   Unnamed: 0  index      tweet_id created_datetime  \\\n",
       "0           0      0  1.000014e+17       2011-08-07   \n",
       "1           1      1  1.000016e+18       2018-05-25   \n",
       "2           2      2  1.000017e+18       2018-05-25   \n",
       "3           5      5  1.000040e+17       2011-08-07   \n",
       "4           7      7  1.000055e+18       2018-05-25   \n",
       "\n",
       "                                             content    author_id  \\\n",
       "0           Bear Grylls just bit a trout's head off!   18003609.0   \n",
       "1        @StacyGSG love the Jets t-shirt on the bear  596144748.0   \n",
       "2  Kid: what is this this is boring. I wish it wa...   31197211.0   \n",
       "3  Making hubby jealous (@ Big Bear Valley Sports...   19245601.0   \n",
       "4        Yep. Only one Bear. https://t.co/WfUOioWGmd  415006664.0   \n",
       "\n",
       "           place_id           location   longitude   latitude  \\\n",
       "0  fbd6d2f5a4e4a15e    California, USA -120.645800  35.247868   \n",
       "1  a592bd6ceb1319f7      San Diego, CA -117.109730  32.801037   \n",
       "2  0c2e6999105f8070        Anaheim, CA -117.829060  33.810070   \n",
       "3  17fe6350a3570c69  Big Bear Lake, CA -116.866684  34.259740   \n",
       "4  fbd6d2f5a4e4a15e    California, USA -119.311030  37.250366   \n",
       "\n",
       "            county                                   tokenized_tweets  \\\n",
       "0  SAN LUIS OBISPO  ([bear, grylls, bit, trout, head], bear grylls...   \n",
       "1        SAN DIEGO    ([love, jet, shirt, bear], love jet shirt bear)   \n",
       "2           ORANGE  ([kid, boring, wish, mickey, mouse, club, pare...   \n",
       "3   SAN BERNARDINO  ([making, hubby, jealous, big, bear, valley, s...   \n",
       "4           MADERA                   ([yep, one, bear], yep one bear)   \n",
       "\n",
       "                                           tokenized  \\\n",
       "0                   [bear, grylls, bit, trout, head]   \n",
       "1                           [love, jet, shirt, bear]   \n",
       "2  [kid, boring, wish, mickey, mouse, club, paren...   \n",
       "3  [making, hubby, jealous, big, bear, valley, sp...   \n",
       "4                                   [yep, one, bear]   \n",
       "\n",
       "                                              merged  \n",
       "0                         bear grylls bit trout head  \n",
       "1                                love jet shirt bear  \n",
       "2  kid boring wish mickey mouse club parent quiet...  \n",
       "3  making hubby jealous big bear valley sportsman...  \n",
       "4                                       yep one bear  "
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new = pd.read_csv(\"../filtered.csv\")\n",
    "new['tokenized_tweets'] = new['content'].apply(lambda x: text_clean_and_tokenize(x))\n",
    "new[['tokenized', 'merged']] = new['tokenized_tweets'].apply(lambda x: pd.Series(x))\n",
    "new['created_datetime'] = pd.to_datetime(new['created_datetime'])\n",
    "new.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "AqgWWZ5nX_sF",
    "outputId": "52a913f6-6c32-42e3-be38-28dd773786fb"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(40000, 3524)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_sub = new.iloc[40000: 80000].copy()\n",
    "X_new = new_sub['merged']\n",
    "\n",
    "X_new_vectors = tfidf.transform(X_new)\n",
    "X_new_vectors.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "pp4MI5vBp0aQ",
    "outputId": "2a53a1b2-bcd1-4700-8f16-ee94e6a6713d"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /root/nltk_data...\n",
      "[nltk_data]   Unzipping taggers/averaged_perceptron_tagger.zip.\n"
     ]
    }
   ],
   "source": [
    "selected_features_nb = np.loadtxt('selected_features_nb.txt', delimiter='\\t')\n",
    "selected_features_rf = np.loadtxt('selected_features_rf.txt', delimiter='\\t')\n",
    "y_pred_nb, y_pred_rf, y_pred_svm, y_pred_lr, y_pred_ada, y_pred_aug = merge_models(X_vectors, X_new_vectors, X, X_new, y,\n",
    "                                                                                   selected_features_nb, selected_features_rf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BCG8Y8TFhxD1"
   },
   "outputs": [],
   "source": [
    "new_sub['y_pred_nb'] = y_pred_nb\n",
    "new_sub['y_pred_rf'] = y_pred_rf\n",
    "new_sub['y_pred_svm'] = y_pred_svm\n",
    "new_sub['y_pred_lr'] = y_pred_lr\n",
    "new_sub['y_pred_ada'] = y_pred_ada\n",
    "new_sub['y_pred_aug'] = y_pred_aug\n",
    "# new_sub.to_csv(f'../test_labels.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ceDguCoszU6x"
   },
   "source": [
    "To obtain a combined prediction, we appended the predictions generated by each of the six models to the existing dataframe. We then calculated the mode of these predictions, which we saved as a new column in the dataframe. The following example provides a clear illustration of the format by providing the records that were predicted as 1 by **at least 4 models (threshold)**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qOehEGxfk504"
   },
   "outputs": [],
   "source": [
    "target_labels = ['y_pred_nb','y_pred_rf','y_pred_svm','y_pred_lr','y_pred_ada','y_pred_aug']\n",
    "vote = []\n",
    "for i in range(len(new_sub)):\n",
    "    temp = new_sub.iloc[i][target_labels]\n",
    "    vote.append(Counter(temp).most_common())\n",
    "\n",
    "new_sub['vote'] = vote\n",
    "new_sub.to_csv(f'../test_labels.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "QqisnXFhmBrf",
    "outputId": "cb2338d4-14f0-4fdb-848a-46adc025ad27"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5513 {1: 6} #drinklocal #craftbeer #beerporn #craftbeerguy #drinkcraft @pizzaportcarlsbad Rippin Bear #collaboration with @esbcbrews #cacraftbeer #independentbeer #supportlocalbeer #supportcraftbeer #properpour #properglassware https://t.co/cle0iL5oX7\n",
      "5523 {1: 6} THERE WAS ONE MATCH! said Grumpy Bear. https://t.co/uwQCUBLyCJ https://t.co/N1ECMITNrb\n",
      "5525 {1: 6} @CShalby Big Bear or one of the little lakes around Tahoe? Very pretty \n",
      "5526 {1: 6} There's a bear in this picture. #WannaGetAway #Yosemite National Park https://t.co/EAyD12hxn5\n",
      "5545 {1: 5, 2: 1} @RagingWaters Does a bear sh*t in the woods? #yes\n",
      "5556 {1: 4, 0: 2} @sundayjeff I vividly remember the care bear craze and my parents getting me Lucky and my brorhers and sisters other ones.  I had to of been about 7 https://t.co/e8k969Wc8h\n",
      "5562 {1: 6} @DeborahNetburn @DeborahNetburn whattaabout this bear of a bear \n",
      "5568 {1: 4, 0: 2} As the world warms &amp; Arctic sea ice thins, starving polar bears are being driven ever further south, where they meet grizzlies, whose ranges are expanding northwards. And with that growing contact between the two species comes more mating. https://t.co/1DOsiGJ082\n",
      "5597 {1: 6} @NatlParkService Seeing not only one bear in the wild for the first time  @YellowstoneNPS - but TWO! Also seeing Moose for the first time @RockyNPS @NikonUSA #leaveordinarybehind #fulltimerv #rvlife @GoRVing @RVcom #getoutside #ExploreOurNation https://t.co/M3YqnYZWV3\n",
      "5599 {1: 5, 0: 1} @nina_in_LA California bear.\n",
      "5601 {1: 5, 0: 1} @AnthonyGugino1 @ABC Its a California black bear. They come in brown too, but the specific line is called black. \n",
      "5604 {1: 5, 0: 1} Bear bottom barebacked \n",
      ".\n",
      ".\n",
      ".\n",
      "https://t.co/63p4VFWZl7\n",
      "\n",
      " https://t.co/CCHHEOM5Ft\n",
      "5606 {1: 4, 0: 2} @lyssat23 s Kodiak bear plush !!! https://t.co/GywxO20epe\n",
      "5608 {1: 5, 0: 1} Coming back to NYC in June, looking for new nanny for Bear; 20 hours a week (can do more if a barrier), afternoons and evenings.\n",
      "5612 {1: 5, 2: 1} save the polar bears...check out out polar bear cake pops #ArcticHome http://t.co/78yVQuX7\n",
      "5614 {1: 5, 0: 1} Sexy Baby Bear! Yum  https://t.co/pp8G89Hhrv\n",
      "5616 {1: 5, 0: 1} Bear bro of Taeshon https://t.co/PtPBQwd5ZZ\n",
      "5617 {1: 5, 0: 1} @TiaLoops @cellabella16 Bob oso  = handsome bear ?\n",
      "5624 {1: 6} The Bear roars!  #LetsGoOilers 2-0\n",
      "5633 {1: 5, 0: 1} A woman was found dead after an apparent bear attack in Colorado\n",
      "\n",
      "https://t.co/gHhFaXxrfs\n",
      "5642 {1: 6} Booboo Stewart...OMG. Be my cuddle bear.\n",
      "5648 {1: 5, 0: 1} Bear Cubs giving back to the community. Its more than football #CB4L https://t.co/APevzEzQUH\n",
      "5662 {1: 4, 2: 1, 0: 1} @Cheri_Chapstick @LuvMeDommie night Cher-Bear\n",
      "5663 {1: 6} @Matt_Velazquez Two donuts, one foe each shot. Or maybe just one large bear claw?\n",
      "5665 {1: 6} Builld-a-Bear https://t.co/fRGPZ0Qaoy\n",
      "5667 {1: 4, 0: 2} If youre responsible for the bear stunt and we know each other, slide into my DMs so I can tell you to NOT.\n",
      "5671 {1: 4, 0: 2} Close encounters of the bear kind https://t.co/GqfksDsxcj\n",
      "5695 {1: 6} Polar Bear is quite civilized  @ Temescal Regional Recreational Area https://t.co/JTnShc5KOt\n",
      "5710 {1: 6} @NikkiMedoro What's the Bear Up too \n",
      "5717 {1: 4, 0: 2} @thehill This is disgusting. That bear is not entertainment for your personal gain\n",
      "5718 {1: 5, 0: 1} @grizzlygirl87 Im going with polar bear because of the pronounced beardonkadonk.\n",
      "5723 {1: 6} @nycsouthpaw Exit prevented by a bear.\n",
      "5733 {1: 6} @CBSLA Impressive Bear\n",
      "5738 {1: 5, 0: 1} @MollyJongFast @traytaymakeup Animal cruelty @beastjohncox Nobody in California is going to vote for you. Stop abusing that bear!\n",
      "5740 {1: 5, 2: 1} @madrid_mike How do you know the bear wont completely change things this time around ?\n",
      "5746 {1: 6} @KTVU What a fucking idiot and poor bear\n",
      "5750 {1: 6} Human remains found in 2 bears suspected in Colorado attack https://t.co/nrWVmUVjeq via @nypost\n",
      "\n",
      "Whats fucked here is that they euthanized a mommy bear and her 2 cubs. For what? Because some stupid woman went for a walk on their dinner plate? This is ridiculous.\n",
      "5753 {1: 6} @laura_nelson @mattdpearce Cruelty to the bear!!\n",
      "5755 {1: 6} He didnt bring the bear to this one, but businessman John Cox made a campaign stop outside the French Laundry yesterday to rub in governor Newsoms misstep there last year. @kcbsradio @ The French Laundry https://t.co/4AcURwoYpB\n",
      "5762 {1: 5, 0: 1} @elerianm @FerroTV @lisaabramowicz1 @tomkeene Fully invested bear   :-)\n",
      "5784 {1: 6} @PGPImages @Mr_Mike_Clarke I'm assuming you are not draped in a polar bear so what are you wearing there?\n",
      "5798 {1: 4, 0: 2} I hope the bear gets fed up and tears this PO a new one. https://t.co/zRqfHR20M7\n",
      "5808 {1: 6} @TylerTMC This bear vs. Ben https://t.co/QElKQqmcAV\n",
      "5809 {1: 6} Saw my first bear ever in the woods while driving through Cali \n",
      "5834 {1: 5, 0: 1} Im so excited!! Bear is coming back today!!!\n",
      "5841 {1: 4, 0: 2} @AWDtwit @GabeDelArt Babjo radiating some \"Humphrey the bear\" energy\n",
      "5852 {1: 6} bear stop calling me out lol https://t.co/rGPIFtb9J3\n",
      "5855 {1: 4, 0: 2} Republicans begging for a recall then getting stuck with Caitlyn Jenner and some dude dragging a bear around is Coen Brothers level comedy.\n",
      "5862 {1: 4, 2: 1, 0: 1} Stop Candidate From Using Bear As Political Publicity: https://t.co/kpBg6zuETQ\n",
      "5875 {1: 5, 2: 1} HELP THE BEAR\n",
      "5879 {1: 6} @BrandonYounger @ken_erlan @GunnHighPrin @DonAustin_SUP This is written by mama bear, I can tell\n",
      "5906 {1: 6} I just saw Coxs first campaign commercial for governor of California. What a clown  Also, the way he is parading that poor bear around is clearly animal abuse.\n",
      "5908 {1: 4, 0: 2} @MissEloof There is a margarita in my bear future.\n",
      "5915 {1: 6} In bear alley just saw Chris brown!!!:o\n",
      "5922 {1: 6} Swear I just saw a bear on the freeway \n",
      "5926 {1: 6} @BeastJohnCox @GavinNewsom Feed Newsom to the BEAR!\n",
      "5928 {1: 5, 0: 1} @BeastJohnCox Animal abuse. Stop with the bear. Its sad and disgusting.\n",
      "5930 {1: 5, 0: 1} What kind of bear is this? \n",
      "\n",
      ": @brain1anguage @ Little Bear Bar https://t.co/URaVyVA2Wc\n",
      "5938 {1: 6} @ThatUmbrella @SicSexSix @DeadwoodDale @TorJohnson6 Lucha Bear Mask https://t.co/HyMHzagWMF\n",
      "5940 {1: 6} Omg I saw this bear !! We were always at Walmart and its right in front of the door hahah. I might even have a picture with it https://t.co/hR6c4xpUfP\n",
      "5941 {1: 4, 0: 2} @Korinke Reminds of a candidate that dressed up as a bear. Kinda.\n",
      "5945 {1: 6} @MaraOrChristine @MollyJongFast So fucking embarrassing. For the poor bear.\n",
      "5946 {1: 6} @iamPsychoRy The fucking bear  https://t.co/Gwi6bXxjAw\n",
      "5949 {1: 6} Sleeby sun bear https://t.co/OihNKkJ8Tb\n",
      "5952 {1: 6} Creasy Bear! https://t.co/GEbVRjQJtv\n",
      "5956 {1: 6} @maxkonnorxxx Omg how about a sexy bear Cub \n",
      "5963 {1: 6} Preppy bear  @ Japantown https://t.co/zRoALLyzZX\n",
      "5971 {1: 6} Bear saw some clips of a @kylie_welker match - might get him interested in real wrestling yet!\n",
      "5972 {1: 6} Apparently a black bear was walking down the street in San Anselmo a few minutes ago.  About a mile from me.  Now up in a tree.   Weve got everything here.  Bobcats and now black bears.  Weve had coyotes.  What more could you ask for? https://t.co/BGyJMRhDpE\n",
      "5974 {1: 6} My new neighbors moved in and arent from around here.  Asked if it was normal to have a bear in the tree.  \n",
      "\n",
      "https://t.co/tMUj850k49\n",
      "5981 {1: 6} (//_-) @soleild you didn't see it either. wahhhh! (\"\\(TT_TT)/\") [crying baby bear]\n",
      "5991 {1: 6} @BeastJohnCox @GavinNewsom Feed him to your BEAR! #RecallGavinNewsom\n"
     ]
    }
   ],
   "source": [
    "l, r = 5500, 6000\n",
    "for i in range(l, r):\n",
    "  votes = dict(new_sub.iloc[i].vote)\n",
    "  try:\n",
    "    if votes[1] >= 4:\n",
    "        print(i, votes, new_sub.iloc[i].content)\n",
    "  except: continue"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "x4CRwEYys9ct"
   },
   "source": [
    "### Implementing an ensemble model to generate a target subset for manual labeling by CDFW\n",
    "\n",
    "Using ensemble model votes from 6 text classification models, we can automatically predict the labels for unlabeled data and create a subset of records predicted as 1 or 2. This subset can then be sent to CDFW environmental scientists for manual labeling. \n",
    "\n",
    "This approach is highly efficient as **it significantly narrows down the range of data and improves the handling of imbalanced data (only ~5% class 1 data)**, ultimately saving time and resources required for manual labeling. On the other hand, having the dataset labeled by CDFW Environmental Scientists would result in a higher level of accuracy and greatly improve the reliability of the entire pipeline and ensemble model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Rp8eau5Jq2w7"
   },
   "outputs": [],
   "source": [
    "unlabeled = pd.read_csv('../test_labels.csv')\n",
    "labeled = merge_csv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "GEtA5VMNvplm",
    "outputId": "316c6f57-e856-4b73-febd-f868a8e92f08"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 40000 entries, 0 to 39999\n",
      "Data columns (total 21 columns):\n",
      " #   Column            Non-Null Count  Dtype  \n",
      "---  ------            --------------  -----  \n",
      " 0   Unnamed: 0        40000 non-null  int64  \n",
      " 1   index             40000 non-null  int64  \n",
      " 2   tweet_id          40000 non-null  float64\n",
      " 3   created_datetime  40000 non-null  object \n",
      " 4   content           40000 non-null  object \n",
      " 5   author_id         40000 non-null  float64\n",
      " 6   place_id          37355 non-null  object \n",
      " 7   location          37355 non-null  object \n",
      " 8   longitude         40000 non-null  float64\n",
      " 9   latitude          40000 non-null  float64\n",
      " 10  county            40000 non-null  object \n",
      " 11  tokenized_tweets  40000 non-null  object \n",
      " 12  tokenized         40000 non-null  object \n",
      " 13  merged            39955 non-null  object \n",
      " 14  y_pred_nb         40000 non-null  int64  \n",
      " 15  y_pred_rf         40000 non-null  int64  \n",
      " 16  y_pred_svm        40000 non-null  int64  \n",
      " 17  y_pred_lr         40000 non-null  int64  \n",
      " 18  y_pred_ada        40000 non-null  int64  \n",
      " 19  y_pred_aug        40000 non-null  int64  \n",
      " 20  vote              40000 non-null  object \n",
      "dtypes: float64(4), int64(8), object(9)\n",
      "memory usage: 6.4+ MB\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 7112 entries, 0 to 8720\n",
      "Data columns (total 10 columns):\n",
      " #   Column            Non-Null Count  Dtype         \n",
      "---  ------            --------------  -----         \n",
      " 0   tweet_id          7112 non-null   float64       \n",
      " 1   created_datetime  7112 non-null   datetime64[ns]\n",
      " 2   content           7112 non-null   object        \n",
      " 3   author_id         7112 non-null   float64       \n",
      " 4   place_id          6946 non-null   object        \n",
      " 5   location          6944 non-null   object        \n",
      " 6   longitude         7112 non-null   float64       \n",
      " 7   latitude          7112 non-null   float64       \n",
      " 8   county            7112 non-null   object        \n",
      " 9   label             7112 non-null   int64         \n",
      "dtypes: datetime64[ns](1), float64(4), int64(1), object(4)\n",
      "memory usage: 611.2+ KB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(None, None)"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unlabeled.info(), labeled.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qbpnyoxL3Rba"
   },
   "source": [
    "#### Here, we are assigning unique labels to each record by taking the mode of the 6 models' prediction votes. This process applies to text data, and ensures consistency and accuracy in labeling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vH6hkWz6zi0p"
   },
   "outputs": [],
   "source": [
    "import ast\n",
    "\n",
    "def extract_first_value(lst):\n",
    "    if isinstance(lst, str):\n",
    "        lst = ast.literal_eval(lst)\n",
    "    if isinstance(lst, list) and len(lst) > 0:\n",
    "        return lst[0][0]\n",
    "    else:\n",
    "        return np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "HRucJD9EmTHn",
    "outputId": "4c9a9d76-056d-40f4-8e9c-039965f430b5"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tweet_id            46888\n",
       "created_datetime    46888\n",
       "content             46888\n",
       "author_id           46888\n",
       "place_id            44088\n",
       "location            44086\n",
       "longitude           46888\n",
       "latitude            46888\n",
       "county              46888\n",
       "y_pred_nb           40000\n",
       "y_pred_rf           40000\n",
       "y_pred_svm          40000\n",
       "y_pred_lr           40000\n",
       "y_pred_ada          40000\n",
       "y_pred_aug          40000\n",
       "vote                40000\n",
       "label               46888\n",
       "dtype: int64"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "concatenated_df = pd.concat([unlabeled, labeled], axis=0)\n",
    "concatenated_df.drop_duplicates(subset=['tweet_id','content'], inplace=True)\n",
    "concatenated_df['label'] = concatenated_df['label'].fillna(concatenated_df['vote'].apply(extract_first_value))\n",
    "concatenated_df.drop(['Unnamed: 0','index','tokenized_tweets', 'tokenized', 'merged'], axis=1, inplace=True)\n",
    "concatenated_df.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ouuuPKIv35lJ"
   },
   "source": [
    "To avoid any disturbance, I have dropped any records that are unrelated to labelling and have only kept four necessary features: tweet_id, created_datetime, county, and content."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Mw2J0a6TwYI4",
    "outputId": "1bdd7179-6373-4b7e-ef3c-19affee42377"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 8843 entries, 0 to 8842\n",
      "Data columns (total 17 columns):\n",
      " #   Column            Non-Null Count  Dtype  \n",
      "---  ------            --------------  -----  \n",
      " 0   tweet_id          8843 non-null   float64\n",
      " 1   created_datetime  8843 non-null   object \n",
      " 2   content           8843 non-null   object \n",
      " 3   author_id         8843 non-null   float64\n",
      " 4   place_id          8660 non-null   object \n",
      " 5   location          8660 non-null   object \n",
      " 6   longitude         8843 non-null   float64\n",
      " 7   latitude          8843 non-null   float64\n",
      " 8   county            8843 non-null   object \n",
      " 9   y_pred_nb         7792 non-null   float64\n",
      " 10  y_pred_rf         7792 non-null   float64\n",
      " 11  y_pred_svm        7792 non-null   float64\n",
      " 12  y_pred_lr         7792 non-null   float64\n",
      " 13  y_pred_ada        7792 non-null   float64\n",
      " 14  y_pred_aug        7792 non-null   float64\n",
      " 15  vote              7792 non-null   object \n",
      " 16  label             8843 non-null   float64\n",
      "dtypes: float64(11), object(6)\n",
      "memory usage: 1.1+ MB\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 8843 entries, 0 to 8842\n",
      "Data columns (total 4 columns):\n",
      " #   Column            Non-Null Count  Dtype  \n",
      "---  ------            --------------  -----  \n",
      " 0   tweet_id          8843 non-null   float64\n",
      " 1   created_datetime  8843 non-null   object \n",
      " 2   county            8843 non-null   object \n",
      " 3   content           8843 non-null   object \n",
      "dtypes: float64(1), object(3)\n",
      "memory usage: 276.5+ KB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(None, None)"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "true_labels_labeled = concatenated_df.loc[concatenated_df['label']>0].copy()\n",
    "true_labels_labeled = true_labels_labeled.reset_index(drop=True)\n",
    "true_labels_unlabeled = true_labels_labeled[['tweet_id','created_datetime','county','content']].copy()\n",
    "true_labels_labeled.info(), true_labels_unlabeled.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QFaVI2R-mSAy"
   },
   "outputs": [],
   "source": [
    "concatenated_df.to_csv(f'../test_labels_total.csv', index=False) \n",
    "true_labels_labeled.to_csv(f'../test_labels_labeled.csv', index=False) # for comparison review\n",
    "true_labels_unlabeled.to_csv(f'../test_labels_unlabeled.csv', index=False) # for CDFW labeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "A5X1SrlsjjGN"
   },
   "source": [
    "# Appendix: Rematch tweet_id for missing id records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WhcqBlRfLFPM"
   },
   "outputs": [],
   "source": [
    "no_index = pd.read_csv(\"stage_0_labeled.csv\")\n",
    "total = pd.read_csv(\"../after_filtering.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sySw6-hpLWLm"
   },
   "outputs": [],
   "source": [
    "for index, row in labeled.iterrows():\n",
    "    match = total.loc[total['content'] == row['content']]\n",
    "    if not match.empty:\n",
    "        no_index.at[index, 'tweet_id'] = match.iloc[0]['tweet_id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 357
    },
    "id": "N8bXUgnWL_CC",
    "outputId": "7644fc98-9e8c-47ba-cb54-030bb50697bf"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "  <div id=\"df-57091c2f-5582-4b54-8ca0-f67f1e2d6cac\">\n",
       "    <div class=\"colab-df-container\">\n",
       "      <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>created_datetime</th>\n",
       "      <th>content</th>\n",
       "      <th>author_id</th>\n",
       "      <th>place_id</th>\n",
       "      <th>location</th>\n",
       "      <th>longitude</th>\n",
       "      <th>latitude</th>\n",
       "      <th>county</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6.660000e+17</td>\n",
       "      <td>11/14/15</td>\n",
       "      <td>We named him bear  https://t.co/ELBe2XDuE3</td>\n",
       "      <td>8.358074e+08</td>\n",
       "      <td>f95304ef80fecc3f</td>\n",
       "      <td>Temecula, CA</td>\n",
       "      <td>-117.083496</td>\n",
       "      <td>33.522667</td>\n",
       "      <td>RIVERSIDE</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.411577e+18</td>\n",
       "      <td>7/4/21</td>\n",
       "      <td>My family went camping for the weekend and a b...</td>\n",
       "      <td>1.280000e+18</td>\n",
       "      <td>2da132a7bfebfc0c</td>\n",
       "      <td>Montebello, CA</td>\n",
       "      <td>-118.148735</td>\n",
       "      <td>33.996094</td>\n",
       "      <td>LOS ANGELES</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.050000e+17</td>\n",
       "      <td>2/23/13</td>\n",
       "      <td>Now nobody can call me Kota Bear  . </td>\n",
       "      <td>5.775653e+08</td>\n",
       "      <td>c201deec6d7ba944</td>\n",
       "      <td>Eureka, CA</td>\n",
       "      <td>-124.165910</td>\n",
       "      <td>40.791000</td>\n",
       "      <td>HUMBOLDT</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7.116732e+17</td>\n",
       "      <td>3/20/16</td>\n",
       "      <td>@CalAlumni81 @GoldenBlogs @Berroya I have seve...</td>\n",
       "      <td>2.595895e+07</td>\n",
       "      <td>d35feae19d268b09</td>\n",
       "      <td>Seal Beach, CA</td>\n",
       "      <td>-118.046540</td>\n",
       "      <td>33.723835</td>\n",
       "      <td>ORANGE</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.414504e+17</td>\n",
       "      <td>12/7/14</td>\n",
       "      <td>ProudUSACongress\\ndeclaredWAR\\nonRussia!\\nRuss...</td>\n",
       "      <td>5.397218e+08</td>\n",
       "      <td>4265ece9285a2872</td>\n",
       "      <td>Palm Springs, CA</td>\n",
       "      <td>-116.534090</td>\n",
       "      <td>33.777910</td>\n",
       "      <td>RIVERSIDE</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-57091c2f-5582-4b54-8ca0-f67f1e2d6cac')\"\n",
       "              title=\"Convert this dataframe to an interactive table.\"\n",
       "              style=\"display:none;\">\n",
       "        \n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "       width=\"24px\">\n",
       "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
       "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
       "  </svg>\n",
       "      </button>\n",
       "      \n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      flex-wrap:wrap;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "      <script>\n",
       "        const buttonEl =\n",
       "          document.querySelector('#df-57091c2f-5582-4b54-8ca0-f67f1e2d6cac button.colab-df-convert');\n",
       "        buttonEl.style.display =\n",
       "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "        async function convertToInteractive(key) {\n",
       "          const element = document.querySelector('#df-57091c2f-5582-4b54-8ca0-f67f1e2d6cac');\n",
       "          const dataTable =\n",
       "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                     [key], {});\n",
       "          if (!dataTable) return;\n",
       "\n",
       "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "            + ' to learn more about interactive tables.';\n",
       "          element.innerHTML = '';\n",
       "          dataTable['output_type'] = 'display_data';\n",
       "          await google.colab.output.renderOutput(dataTable, element);\n",
       "          const docLink = document.createElement('div');\n",
       "          docLink.innerHTML = docLinkHtml;\n",
       "          element.appendChild(docLink);\n",
       "        }\n",
       "      </script>\n",
       "    </div>\n",
       "  </div>\n",
       "  "
      ],
      "text/plain": [
       "       tweet_id created_datetime  \\\n",
       "0  6.660000e+17         11/14/15   \n",
       "1  1.411577e+18           7/4/21   \n",
       "2  3.050000e+17          2/23/13   \n",
       "3  7.116732e+17          3/20/16   \n",
       "4  5.414504e+17          12/7/14   \n",
       "\n",
       "                                             content     author_id  \\\n",
       "0        We named him bear  https://t.co/ELBe2XDuE3  8.358074e+08   \n",
       "1  My family went camping for the weekend and a b...  1.280000e+18   \n",
       "2           Now nobody can call me Kota Bear  .   5.775653e+08   \n",
       "3  @CalAlumni81 @GoldenBlogs @Berroya I have seve...  2.595895e+07   \n",
       "4  ProudUSACongress\\ndeclaredWAR\\nonRussia!\\nRuss...  5.397218e+08   \n",
       "\n",
       "           place_id          location   longitude   latitude       county  \\\n",
       "0  f95304ef80fecc3f      Temecula, CA -117.083496  33.522667    RIVERSIDE   \n",
       "1  2da132a7bfebfc0c    Montebello, CA -118.148735  33.996094  LOS ANGELES   \n",
       "2  c201deec6d7ba944        Eureka, CA -124.165910  40.791000     HUMBOLDT   \n",
       "3  d35feae19d268b09    Seal Beach, CA -118.046540  33.723835       ORANGE   \n",
       "4  4265ece9285a2872  Palm Springs, CA -116.534090  33.777910    RIVERSIDE   \n",
       "\n",
       "   label  \n",
       "0    0.0  \n",
       "1    1.0  \n",
       "2    0.0  \n",
       "3    0.0  \n",
       "4    0.0  "
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "no_index.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sr279PCOONwe"
   },
   "outputs": [],
   "source": [
    "labeled.to_csv(f'stage_0_labeled.csv', index=False) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "eFUwpNmYjwFX"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
