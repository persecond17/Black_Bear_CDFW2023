{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "db0d255d-00a8-4a60-8cfc-3dd8d4cbfda7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os,rasterio,pyproj\n",
    "import numpy as np\n",
    "import requests\n",
    "import json\n",
    "import time\n",
    "# from geopy.geocoders import Nominatim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "947e0a7c-c592-4d0d-b16b-2d30465c9dca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# iNat data\n",
    "\n",
    "nat = pd.read_csv('iNaturalist_Data/observations-272633.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99194093-a549-422a-bb7a-3b669af6429c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# process and clean iNat data\n",
    "\n",
    "def process_inat(df):\n",
    "    '''\n",
    "    Drop unneccesary columns and extract month, year and day of week.\n",
    "    '''\n",
    "    df.drop(['observed_on_string','user_login','user_name','created_at','updated_at',\n",
    "              'quality_grade', 'license', 'url', 'image_url','sound_url', 'tag_list',\n",
    "              'private_place_guess', 'private_latitude','private_longitude', \n",
    "              'public_positional_accuracy', 'geoprivacy','taxon_geoprivacy', \n",
    "              'coordinates_obscured', 'positioning_method','positioning_device', \n",
    "              'species_guess', 'scientific_name', \n",
    "             ], axis=1, inplace=True)\n",
    "    df['year'] = pd.DatetimeIndex(df['observed_on']).year\n",
    "    df['month'] = pd.DatetimeIndex(df['observed_on']).month\n",
    "    df['dayofweek'] = pd.DatetimeIndex(df['observed_on']).dayofweek\n",
    "    return df\n",
    "\n",
    "\n",
    "\n",
    "def add_county(df):\n",
    "    '''\n",
    "    Add address to each observation and keep only the county in the address.\n",
    "    Uses API call to Nominatim service via the geopy package.\n",
    "    Return Pandas dataframe with county assigned to the observations.\n",
    "    '''\n",
    "    # Begin downloading address data from Nominatim's API through geopy.\n",
    "    # Assign the county data to each observation in the dataframe.\n",
    "    geolocator = Nominatim(user_agent=\"geoapiExercises\")\n",
    "    county = []\n",
    "    geocoords = df[['latitude', 'longitude']].values\n",
    "    for elems in geocoords:\n",
    "        address, _ = geolocator.reverse((f'{elems[0]}, {elems[1]}'))\n",
    "        address = address.split(',')\n",
    "\n",
    "        for i in address:\n",
    "            if 'county' in i.lower():\n",
    "                county.append(i.strip())\n",
    "\n",
    "    df = pd.concat([df, pd.Series(county, name='county')], axis=1)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8005db62-8470-4924-b895-fb773bf37ca1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# NLCD data\n",
    "\n",
    "nlcd_dir = 'Python/data/nlcd_2019_land_cover_l48_20210604/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dabe66e-064a-4664-ae19-3213826746d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# process and clean NLCD data\n",
    "\n",
    "def process_nlcd(nlcd_dir):\n",
    "    # package from https://github.com/makerportal/geospatial-analyses\n",
    "    ################################################################\n",
    "    # Copyright (c) 2020 \n",
    "    # Author: Joshua Hrisko\n",
    "    ################################################################\n",
    "    #\n",
    "    # This code uses the NLCD land cover data from:\n",
    "    # https://www.mrlc.gov/data\n",
    "    # and plots the land cover information using cartopy\n",
    "    #\n",
    "    ################################################################\n",
    "    \n",
    "    '''\n",
    "    This function converts NLCD file to a matrix of longitude, latitude and respective land type code values and saved as csv files.\n",
    "    Refer to https://www.mrlc.gov/data/legends/national-land-cover-database-class-legend-and-description for legend.\n",
    "    '''\n",
    "    \n",
    "    nlcd_files = [ii for ii in os.listdir(nlcd_dir) if ii[0]!='.']\n",
    "    nlcd_filename = [ii for ii in nlcd_files if ii.endswith('.img')][0]\n",
    "    legend = np.array([0,11,12,21,22,23,24,31,41,42,43,51,52,71,72,73,74,81,82,90,95])\n",
    "    leg_str = np.array(['No Data','Open Water','Perennial Ice/Snow','Developed, Open Space','Developed, Low Intensity',\n",
    "           'Developed, Medium Intensity','Developed High Intensity','Barren Land (Rock/Sand/Clay)',\n",
    "           'Deciduous Forest','Evergreen Forest','Mixed Forest','Dwarf Scrub','Shrub/Scrub',\n",
    "           'Grassland/Herbaceous','Sedge/Herbaceous','Lichens','Moss','Pasture/Hay','Cultivated Crops',\n",
    "           'Woody Wetlands','Emergent Herbaceous Wetlands'])\n",
    "    # colormap determination and setting bounds\n",
    "    with rasterio.open(nlcd_dir+nlcd_filename) as r:\n",
    "        try:\n",
    "            oviews = r.overviews(1) # list of overviews from biggest to smallest\n",
    "            oview = oviews[6] # we grab a smaller view, since we're plotting the entire USA\n",
    "            print('Decimation factor= {}'.format(oview))\n",
    "            # NOTE this is using a 'decimated read' (http://rasterio.readthedocs.io/en/latest/topics/resampling.html)\n",
    "            nlcd = r.read(1, out_shape=(1, int(r.height // oview), int(r.width // oview)))\n",
    "\n",
    "\n",
    "            # Or if you see an interesting feature and want to know the spatial coordinates:\n",
    "            row,col = np.meshgrid(np.arange(0,r.height-(oview),oview),np.arange(0,r.width-oview,oview))\n",
    "            east, north = r.xy(row,col) # image --> spatial coordinates\n",
    "            east = np.ravel(east); north = np.ravel(north) # collapse coordinates for efficient transformation\n",
    "\n",
    "            \n",
    "\n",
    "            tfm = pyproj.transformer.Transformer.from_crs(r.crs,'epsg:4326') # transform for raster image coords to lat/lon\n",
    "            lat,lon = tfm.transform(east,north) # transform the image coordinates\n",
    "            lons = np.reshape(lon,np.shape(row)) # reshape to grid\n",
    "            lats = np.reshape(lat,np.shape(col)) # reshape to grid\n",
    "            \n",
    "    \n",
    "\n",
    "    df_nlcd = pd.DataFrame(nlcd.T)\n",
    "    df_nlcd.to_csv('nlcd/nlcd.csv')\n",
    "    df_lats = pd.DataFrame(lats)\n",
    "    df_lats.to_csv('nlcd/lats.csv')\n",
    "    df_lons = pd.DataFrame(lons)\n",
    "    df_lons.to_csv('nlcd/lons.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2156b575-0111-4f7b-aab6-a6ab43bf2c79",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot NLCD map\n",
    "\n",
    "# package from https://github.com/makerportal/geospatial-analyses\n",
    "\n",
    "################################################################\n",
    "# Copyright (c) 2020 \n",
    "# Author: Joshua Hrisko\n",
    "################################################################\n",
    "#\n",
    "# This code uses the NLCD land cover data from:\n",
    "# https://www.mrlc.gov/data\n",
    "# and plots the land cover information using cartopy\n",
    "#\n",
    "################################################################\n",
    "#\n",
    "#\n",
    "####### import headers #######\n",
    "import os,rasterio,pyproj\n",
    "import numpy as np\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import ListedColormap\n",
    "import cartopy.io.shapereader as shpreader\n",
    "import cartopy.crs as ccrs\n",
    "import cartopy.io.img_tiles as tiles\n",
    "import matplotlib.ticker as mticker\n",
    "from cartopy.mpl.gridliner import LONGITUDE_FORMATTER, LATITUDE_FORMATTER\n",
    "from cartopy.feature import ShapelyFeature\n",
    "import cartopy.feature as cfeature\n",
    "\n",
    "bbox = [-130.2328,21.7423,-63.6722,52.8510] # bounding box for continental USA\n",
    "# bbox = [-124.409591, 32.534156, -114.131211, 42.009518] # bounding box for California\n",
    "\n",
    "#\n",
    "#\n",
    "##########################################\n",
    "# NLCD plotter\n",
    "##########################################\n",
    "#\n",
    "# \n",
    "def plot_nlcd():\n",
    "    nlcd_dir = 'Python/data/nlcd_2019_land_cover_l48_20210604/' # local directory where NLCD folder is located\n",
    "    nlcd_files = [ii for ii in os.listdir(nlcd_dir) if ii[0]!='.']\n",
    "    nlcd_filename = [ii for ii in nlcd_files if ii.endswith('.img')][0]\n",
    "    legend = np.array([0,11,12,21,22,23,24,31,41,42,43,51,52,71,72,73,74,81,82,90,95])\n",
    "    leg_str = np.array(['No Data','Open Water','Perennial Ice/Snow','Developed, Open Space','Developed, Low Intensity',\n",
    "           'Developed, Medium Intensity','Developed High Intensity','Barren Land (Rock/Sand/Clay)',\n",
    "           'Deciduous Forest','Evergreen Forest','Mixed Forest','Dwarf Scrub','Shrub/Scrub',\n",
    "           'Grassland/Herbaceous','Sedge/Herbaceous','Lichens','Moss','Pasture/Hay','Cultivated Crops',\n",
    "           'Woody Wetlands','Emergent Herbaceous Wetlands'])\n",
    "    # colormap determination and setting bounds\n",
    "    with rasterio.open(nlcd_dir+nlcd_filename) as r:\n",
    "        try:\n",
    "            oviews = r.overviews(1) # list of overviews from biggest to smallest\n",
    "            oview = oviews[6] # we grab a smaller view, since we're plotting the entire USA\n",
    "            print('Decimation factor= {}'.format(oview))\n",
    "            # NOTE this is using a 'decimated read' (http://rasterio.readthedocs.io/en/latest/topics/resampling.html)\n",
    "            nlcd = r.read(1, out_shape=(1, int(r.height // oview), int(r.width // oview)))\n",
    "\n",
    "\n",
    "            # Or if you see an interesting feature and want to know the spatial coordinates:\n",
    "            row,col = np.meshgrid(np.arange(0,r.height-(oview),oview),np.arange(0,r.width-oview,oview))\n",
    "            east, north = r.xy(row,col) # image --> spatial coordinates\n",
    "            east = np.ravel(east); north = np.ravel(north) # collapse coordinates for efficient transformation\n",
    "\n",
    "            \n",
    "\n",
    "            tfm = pyproj.transformer.Transformer.from_crs(r.crs,'epsg:4326') # transform for raster image coords to lat/lon\n",
    "            lat,lon = tfm.transform(east,north) # transform the image coordinates\n",
    "            lons = np.reshape(lon,np.shape(row)) # reshape to grid\n",
    "            lats = np.reshape(lat,np.shape(col)) # reshape to grid\n",
    "            \n",
    "\n",
    "            # colormap determination and setting bounds\n",
    "            cmap_in = r.colormap(1) # get colormap information\n",
    "            cmap_in = [[np.float(jj)/255.0 for jj in cmap_in[ii]] for ii in cmap_in] # format colormap for matplotlib\n",
    "            indx_list = np.unique(nlcd) # find unique NLCD values in image\n",
    "            r_cmap = []    \n",
    "            for ii in legend:\n",
    "                r_cmap.append(cmap_in[ii])\n",
    "            r_cmap[0] = [0.0,0.0,0.0,1.0]\n",
    "            raster_cmap = ListedColormap(r_cmap) # defining the NLCD specific color map\n",
    "            norm = mpl.colors.BoundaryNorm(legend, raster_cmap.N) # specifying colors based on num. unique points\n",
    "        except:\n",
    "            print('FAILURE') # if there's an issue, print 'FAILURE'\n",
    "\n",
    "    fig = plt.figure(figsize=(12,8)) # figure sizing\n",
    "    ax = fig.add_subplot(1, 1, 1, projection=ccrs.PlateCarree()) # add axis with projection \n",
    "\n",
    "    # This loop is for creation of a legend below the map\n",
    "    custom_lines,custom_colors,custom_strs = [],[],[]\n",
    "    for qq in indx_list:\n",
    "        if qq in legend:\n",
    "            legend_loc = np.where(qq==legend)[0][0]\n",
    "            custom_lines.append(plt.Line2D([0],[0], marker='s',color=raster_cmap(legend_loc), markersize=12,linestyle=''))\n",
    "            custom_colors.append(raster_cmap(legend_loc)) # legend colors\n",
    "            custom_strs.append(leg_str[legend_loc]) # legend strings\n",
    "\n",
    "    ax.set_axis_off() # turn off the frame\n",
    "\n",
    "    # Limit the extent of the map to a small longitude/latitude range.\n",
    "    ax.set_extent([bbox[0],bbox[2],bbox[1],bbox[3]], crs=ccrs.PlateCarree())\n",
    "\n",
    "    # nlcd = np.ma.masked_where(nlcd==127,nlcd) # the gray 'no data' values can be masked, if desired (looks better)\n",
    "\n",
    "    ax.pcolormesh(lons,lats,np.transpose(nlcd), norm=norm,\n",
    "                 alpha=0.6,cmap=raster_cmap) # plotting actual NLCD data\n",
    "\n",
    "    ax2 = fig.add_subplot(414) # subplot for legend\n",
    "    ax2.set_axis_off() # turn off legend frame\n",
    "    leg_plt_save = ax2.legend(custom_lines, custom_strs,fontsize=12,ncol=2,loc='center')\n",
    "    leg_plt_save.get_frame().set_facecolor('#ebebeb') # color for legend\n",
    "    leg_plt_save.set_bbox_to_anchor((0.48,-0.6)) # legend bbox\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2acb554-d12a-4640-a07e-be2b27f19147",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get weather data "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f866dba8-f52a-45b8-b8e4-618e44eabc28",
   "metadata": {},
   "source": [
    "Pulling the required data for all weather stations (~ 4000 stations) for state of CA is not feasible as it will lead to a huge volume problem, given the small scope of this project. The following is proposed as an alternative:\n",
    "\n",
    "1. Get centroid geocoordinates for each county in CA.\n",
    "2. From NOAA, get full list of weather stations operating in CA.\n",
    "3. Find closest neighbour of weather station to centroid of each county.\n",
    "4. Download the required weather data for that county.\n",
    "5. Repeat for rest of the remaining counties.\n",
    "\n",
    "Scrape county geocoordinates from https://en.wikipedia.org/wiki/User:Michael_J/County_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce5b5982-01e4-4c0b-925d-57d55ce03f4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scrape the county geocoordinates using Pandas.\n",
    "# Latitude and longitude coordinates for each county is already represented as the centroid of the county.\n",
    "county_geo = pd.read_html('https://en.wikipedia.org/wiki/User:Michael_J/County_table')\n",
    "county_geo = county_geo[0][['State', 'County [2]', 'Latitude', 'Longitude']]\n",
    "county_geo.rename(columns={'County [2]':'County'}, inplace=True)\n",
    "county_geo['Latitude'] = county_geo['Latitude'].apply(lambda x: x[:-1])\n",
    "county_geo['Longitude'] = county_geo['Longitude'].apply(lambda x: x[1:-1])\n",
    "\n",
    "# Convert the datatypes for latitude and longitude to numerical format.\n",
    "# Assumes that the longitude values for counties in CA are all negative.\n",
    "county_geo['Latitude'] = pd.to_numeric(county_geo['Latitude'], errors='coerce')\n",
    "county_geo['Longitude'] = pd.to_numeric(county_geo['Longitude'], errors='coerce')\n",
    "county_geo['Longitude'] = county_geo['Longitude'] * -1\n",
    "\n",
    "# Limit to only counties in CA\n",
    "ca = county_geo[county_geo['State'] == 'CA']\n",
    "ca.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "204a2b4e-c9b6-408f-9ec2-3c48202f0a7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get geocoordinates of all weather station operating in CA.\n",
    "# Loop through the stations dataset in NOAA API service.\n",
    "stations = []\n",
    "chunks = [0, 1000, 2000, 3000, 4000, 4543]\n",
    "for chunk in chunks:\n",
    "    # Get call to NOAA service\n",
    "    ca_stations = f\"https://www.ncei.noaa.gov/cdo-web/api/v2/stations?locationid=FIPS:06&limit=1000&offset={chunk}\"\n",
    "    head = {'token':'iCCoreQvXIyrYONrDWVhntoJYBKDdbyb'}\n",
    "    response = requests.get(ca_stations, headers=head)\n",
    "\n",
    "    # Process requested data from the API service.\n",
    "    result = json.loads(response.text)\n",
    "    for i in result['results']:\n",
    "        stations.append( (i['id'], i['name'], i['latitude'], i['longitude'], i['maxdate'], i['datacoverage']) )\n",
    "\n",
    "# Convert to dataframe for manipulation\n",
    "all_stations = pd.DataFrame(stations, columns=['station_code', 'name', 'latitude', 'longitude', 'maxdate', 'datacoverage'])\n",
    "\n",
    "# Remove duplicated records\n",
    "all_stations.drop_duplicates(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d6f6021-7dcc-4b59-9ea7-7df1e51a724b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find weather stations closest to county centroid\n",
    "\n",
    "def haversine(lon1, lat1, lon2, lat2):\n",
    "    \"\"\"\n",
    "    Function to calculate the Euclidean distance between two geocoordinates.\n",
    "    Returns Euclidean distance between two geocoordinates.\n",
    "    \"\"\"\n",
    "    # Convert decimal degrees to radians.\n",
    "    lon1, lat1, lon2, lat2 = map(radians, [lon1, lat1, lon2, lat2])\n",
    "\n",
    "    # Haversine formula.\n",
    "    dlon = lon2 - lon1\n",
    "    dlat = lat2 - lat1\n",
    "    a = np.sin(dlat/2) ** 2 + np.cos(lat1) * np.cos(lat2) * np.sin(dlon/2) ** 2\n",
    "    c = 2 * np.arcsin(np.sqrt(a))\n",
    "\n",
    "    # Radius of earth in KM is 6371\n",
    "    km = 6371 * c\n",
    "    return km\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93c3befe-c468-4e96-a2be-ddf9119787c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get closest weather station to the county centroid.\n",
    "\n",
    "closest_station = pd.DataFrame()\n",
    "temp_station = all_stations.copy()\n",
    "for i in range(ca.shape[0]):\n",
    "    lat_county, long_county = ca.iloc[i, 2:4]\n",
    "    temp_station['dist_to_county_centroid'] = temp_station.apply(lambda x: haversine(lat_county, long_county, x['latitude'], x['longitude']), axis=1)\n",
    "    temp_station['county'] = ca.iloc[i, 1]\n",
    "    closest_station = pd.concat([closest_station, temp_station.sort_values('dist_to_county_centroid').head(1)], axis=0)\n",
    "\n",
    "closest_station.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3b81351-d339-4d62-8e12-a5220098cbf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grab temperature data\n",
    "daily_temperature = []\n",
    "startdates = ['2018-01-01', '2019-01-01', '2020-01-01', '2021-01-01', '2022-01-01']\n",
    "enddates =   ['2018-12-31', '2019-12-31', '2020-12-31', '2021-12-31', '2022-12-31']\n",
    "for startdate, enddate in zip(startdates, enddates):\n",
    "    for i in range(closest_station.shape[0]):\n",
    "        station_code = closest_station.iloc[i, 0]\n",
    "\n",
    "        print(f\"Getting temperature data from station {i + 1} of {closest_station.shape[0]} for {startdate} to {enddate}\", end='\\r')\n",
    "        data = f\"https://www.ncei.noaa.gov/cdo-web/api/v2/data?datasetid=GHCND&stationid={station_code}&datatypeid=TMIN&datatypeid=TMAX&startdate={startdate}&enddate={enddate}&units=standard&limit=1000\"\n",
    "        head = {'token':'iCCoreQvXIyrYONrDWVhntoJYBKDdbyb'}\n",
    "        response = requests.get(data, headers=head)\n",
    "        if len(response.text) != 0:\n",
    "            results = json.loads(response.text)\n",
    "            daily_temperature.append(results)\n",
    "\n",
    "        time.sleep(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fe09e17-6e48-46af-8623-0580b74677d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grab percipitation data\n",
    "daily_percipitation = []\n",
    "startdates = ['2018-01-01', '2019-01-01', '2020-01-01', '2021-01-01', '2022-01-01']\n",
    "enddates =   ['2018-12-31', '2019-12-31', '2020-12-31', '2021-12-31', '2022-12-31']\n",
    "for startdate, enddate in zip(startdates, enddates):\n",
    "    for i in range(closest_station.shape[0]):\n",
    "        station_code = closest_station.iloc[i, 0]\n",
    "\n",
    "        print(f\"Getting percipitation data from station {i + 1} of {closest_station.shape[0]} for {startdate} to {enddate}\", end='\\r')\n",
    "        data = f\"https://www.ncei.noaa.gov/cdo-web/api/v2/data?datasetid=GHCND&stationid={station_code}&datatypeid=PRCP&startdate={startdate}&enddate={enddate}&units=standard&limit=500\"\n",
    "        head = {'token':'iCCoreQvXIyrYONrDWVhntoJYBKDdbyb'}\n",
    "        response = requests.get(data, headers=head)\n",
    "        if len(response.text) != 0:\n",
    "            results = json.loads(response.text)\n",
    "            daily_percipitation.append(results)\n",
    "        \n",
    "        time.sleep(0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f60814fa-1ae7-4732-b2a4-ab6f63e2a08e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process results and consolidate into a dataframe\n",
    "temperature = pd.DataFrame()\n",
    "for i in daily_temperature:\n",
    "    if len(i) != 0:\n",
    "        temp = pd.DataFrame(i['results'])\n",
    "        temperature = pd.concat([temperature, temp], axis=0)\n",
    "\n",
    "percipitation = pd.DataFrame()\n",
    "for i in daily_percipitation:\n",
    "    if len(i) != 0:\n",
    "        temp = pd.DataFrame(i['results'])\n",
    "        percipitation = pd.concat([percipitation, temp], axis=0)\n",
    "\n",
    "noaa = pd.concat([temperature, percipitation], axis=0)\n",
    "noaa.drop('attributes', axis=1, inplace=True)\n",
    "noaa['date'] = pd.to_datetime(noaa['date'], errors='coerce')\n",
    "noaa.sort_values(['date', 'station', 'datatype'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d032220-9e81-462a-b223-b8b8ebda81bb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be3d020b-d898-4dc6-b84b-1626ba5058d3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "681b8d7e-db52-4da7-b75c-c32831b40d84",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a41dbf94-3a35-42b1-9461-bde0b8e4645b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d5fb2ab-8eeb-4bd8-981c-e5f083bf27d1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66c59e34-88c0-441c-8f6a-47bdc2313eed",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4e59ce8-05b4-442c-bdc8-47b9805a0a7e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07c0cb10-f264-40cb-b69f-5b6446d9518c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "287fdcdd-1d4c-40c2-936b-2922323a2796",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3aa21d2a-4058-4248-a7af-485810a3f4fd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27fc558a-d340-4c7f-af8b-d61bddb576a1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8ebf3b2-3b3b-43fb-82dd-7688cd82216e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
